\doxysection{node\+\_\+modules/xxhash-\/wasm Directory Reference}
\hypertarget{dir_e1fb642c3e0fc1a052d95b0295820cd9}{}\label{dir_e1fb642c3e0fc1a052d95b0295820cd9}\index{node\_modules/xxhash-\/wasm Directory Reference@{node\_modules/xxhash-\/wasm Directory Reference}}


\doxysubsection{Detailed Description}
\href{https://github.com/jungomi/xxhash-wasm/actions/workflows/nodejs.yml}{\texttt{ }} \href{https://www.npmjs.com/package/xxhash-wasm}{\texttt{ }}

A Web\+Assembly implementation of \href{https://github.com/Cyan4973/xxHash}{\texttt{ xx\+Hash}}, a fast non-\/cryptographic hash algorithm. It can be called seamlessly from Java\+Script. You can use it like any other Java\+Script library but still get the benefits of Web\+Assembly, no special setup needed.\hypertarget{README.md_autotoc_md35835}{}\doxysubsection{\texorpdfstring{Table of Contents}{Table of Contents}}\label{README.md_autotoc_md35835}

\begin{DoxyItemize}
\item \doxylink{README.md_installation}{Installation}
\begin{DoxyItemize}
\item From npm
\item From Unpkg
\begin{DoxyItemize}
\item ES Modules
\item UMD build
\end{DoxyItemize}
\item Cloudflare Workers
\end{DoxyItemize}
\item \doxylink{readme.md_usage}{Usage}
\begin{DoxyItemize}
\item Streaming Example
\item Node
\end{DoxyItemize}
\item Performance
\begin{DoxyItemize}
\item Engine Requirements
\end{DoxyItemize}
\item \doxylink{README.md_api}{API}
\begin{DoxyItemize}
\item h32
\item h64
\item Streaming
\end{DoxyItemize}
\item Comparison to xxhashjs
\begin{DoxyItemize}
\item Benchmarks
\item Bundle size
\end{DoxyItemize}
\end{DoxyItemize}\hypertarget{README.md_autotoc_md35836}{}\doxysubsection{\texorpdfstring{Installation}{Installation}}\label{README.md_autotoc_md35836}
\hypertarget{README.md_autotoc_md35837}{}\doxysubsubsection{\texorpdfstring{From npm}{From npm}}\label{README.md_autotoc_md35837}

\begin{DoxyCode}{0}
\DoxyCodeLine{npm\ install\ -\/-\/save\ xxhash-\/wasm}

\end{DoxyCode}


Or with Yarn\+:


\begin{DoxyCode}{0}
\DoxyCodeLine{yarn\ add\ xxhash-\/wasm}

\end{DoxyCode}
\hypertarget{README.md_autotoc_md35838}{}\doxysubsubsection{\texorpdfstring{From \href{https://unpkg.com/}{\texttt{ Unpkg}}}{From \href{https://unpkg.com/}{\texttt{ Unpkg}}}}\label{README.md_autotoc_md35838}
\hypertarget{README.md_autotoc_md35839}{}\doxysubsubsubsection{\texorpdfstring{ES Modules}{ES Modules}}\label{README.md_autotoc_md35839}

\begin{DoxyCode}{0}
\DoxyCodeLine{<script\ type="{}module"{}>}
\DoxyCodeLine{\ \ import\ xxhash\ from\ "{}https://unpkg.com/xxhash-\/wasm/esm/xxhash-\/wasm.js"{};}
\DoxyCodeLine{</script>}

\end{DoxyCode}
\hypertarget{README.md_autotoc_md35840}{}\doxysubsubsubsection{\texorpdfstring{UMD build}{UMD build}}\label{README.md_autotoc_md35840}

\begin{DoxyCode}{0}
\DoxyCodeLine{<script\ src="{}https://unpkg.com/xxhash-\/wasm/umd/xxhash-\/wasm.js"{}></script>}

\end{DoxyCode}


The global {\ttfamily xxhash} will be available.\hypertarget{README.md_autotoc_md35841}{}\doxysubsubsection{\texorpdfstring{Cloudflare Workers}{Cloudflare Workers}}\label{README.md_autotoc_md35841}
If you are using \href{https://developers.cloudflare.com/workers/}{\texttt{ Cloudflare Workers}} (workerd) you can use the installed npm package as is. The {\ttfamily xxhash-\/wasm} package is compatible with Cloudflare Workers.


\begin{DoxyCode}{0}
\DoxyCodeLine{import\ xxhash\ from\ "{}xxhash-\/wasm"{};}

\end{DoxyCode}


Importing it will pick the correct file base on the \href{https://developers.cloudflare.com/workers/wrangler/bundling/\#conditional-exports}{\texttt{ conditional import}} from the package.\+json.\hypertarget{README.md_autotoc_md35842}{}\doxysubsection{\texorpdfstring{Usage}{Usage}}\label{README.md_autotoc_md35842}
The Web\+Assembly is contained in the Java\+Script bundle, so you don\textquotesingle{}t need to manually fetch it and create a new Web\+Assembly instance.


\begin{DoxyCode}{0}
\DoxyCodeLine{import\ xxhash\ from\ "{}xxhash-\/wasm"{};}
\DoxyCodeLine{}
\DoxyCodeLine{//\ Creates\ the\ WebAssembly\ instance.}
\DoxyCodeLine{xxhash().then(hasher\ =>\ \{}
\DoxyCodeLine{\ \ const\ input\ =\ "{}The\ string\ that\ is\ being\ hashed"{};}
\DoxyCodeLine{}
\DoxyCodeLine{\ \ //\ 32-\/bit\ version}
\DoxyCodeLine{\ \ hasher.h32(input);\ //\ 3998627172\ (decimal\ representation)}
\DoxyCodeLine{\ \ //\ For\ convenience,\ get\ hash\ as\ string\ of\ its\ zero-\/padded\ hex\ representation}
\DoxyCodeLine{\ \ hasher.h32ToString(input);\ //\ "{}ee563564"{}}
\DoxyCodeLine{}
\DoxyCodeLine{\ \ //\ 64-\/bit\ version}
\DoxyCodeLine{\ \ hasher.h64(input);\ //\ 5776724552493396044n\ (BigInt)}
\DoxyCodeLine{\ \ //\ For\ convenience,\ get\ hash\ as\ string\ of\ its\ zero-\/padded\ hex\ representation}
\DoxyCodeLine{\ \ hasher.h64ToString(input);\ //\ "{}502b0c5fc4a5704c"{}}
\DoxyCodeLine{\});}

\end{DoxyCode}


Or with {\ttfamily async}/{\ttfamily await} and destructuring\+:


\begin{DoxyCode}{0}
\DoxyCodeLine{//\ Creates\ the\ WebAssembly\ instance.}
\DoxyCodeLine{const\ \{\ h32,\ h64\ \}\ =\ await\ xxhash();}
\DoxyCodeLine{}
\DoxyCodeLine{const\ input\ =\ "{}The\ string\ that\ is\ being\ hashed"{};}
\DoxyCodeLine{//\ 32-\/bit\ version}
\DoxyCodeLine{h32(input);\ //\ 3998627172\ (decimal\ representation)}
\DoxyCodeLine{//\ 64-\/bit\ version}
\DoxyCodeLine{h64(input);\ //\ 5776724552493396044n\ (BigInt)}

\end{DoxyCode}
\hypertarget{README.md_autotoc_md35843}{}\doxysubsubsection{\texorpdfstring{Streaming Example}{Streaming Example}}\label{README.md_autotoc_md35843}
{\ttfamily xxhash-\/wasm} supports a {\ttfamily crypto}-\/like streaming api, useful for avoiding memory consumption when hashing large amounts of data\+:


\begin{DoxyCode}{0}
\DoxyCodeLine{const\ \{\ create32,\ create64\ \}\ =\ await\ xxhash();}
\DoxyCodeLine{}
\DoxyCodeLine{//\ 32-\/bit\ version}
\DoxyCodeLine{create32()}
\DoxyCodeLine{\ \ .update("{}some\ data"{})}
\DoxyCodeLine{\ \ //\ update\ accepts\ either\ a\ string\ or\ Uint8Array}
\DoxyCodeLine{\ \ .update(Uint8Array.from([1,\ 2,\ 3]))}
\DoxyCodeLine{\ \ .digest();\ //\ 955607085}
\DoxyCodeLine{}
\DoxyCodeLine{//\ 64-\/bit\ version}
\DoxyCodeLine{create64()}
\DoxyCodeLine{\ \ .update("{}some\ data"{})}
\DoxyCodeLine{\ \ //\ update\ accepts\ either\ a\ string\ or\ Uint8Array}
\DoxyCodeLine{\ \ .update(Uint8Array.from([1,\ 2,\ 3]))}
\DoxyCodeLine{\ \ .digest();\ //\ 883044157688673477n}

\end{DoxyCode}
\hypertarget{README.md_autotoc_md35844}{}\doxysubsubsection{\texorpdfstring{Node}{Node}}\label{README.md_autotoc_md35844}
It doesn\textquotesingle{}t matter whether you are using Common\+JS or ES Modules in Node (e.\+g. with {\ttfamily "{}type"{}\+: "{}module"{}} in {\ttfamily package.\+json} or using the explicit file extensions {\ttfamily .cjs} or {\ttfamily .mjs} respectively), importing {\ttfamily xxhash-\/wasm} will always load the corresponding module, as both bundles are provided and specified in the {\ttfamily exports} field of its {\ttfamily package.\+json}, therefore the appropriate one will automatically be selected.

{\bfseries{Using ES Modules}}


\begin{DoxyCode}{0}
\DoxyCodeLine{import\ xxhash\ from\ "{}xxhash-\/wasm"{};}

\end{DoxyCode}


{\bfseries{Using Common\+JS}}


\begin{DoxyCode}{0}
\DoxyCodeLine{const\ xxhash\ =\ require("{}xxhash-\/wasm"{});}

\end{DoxyCode}
\hypertarget{README.md_autotoc_md35845}{}\doxysubsection{\texorpdfstring{Performance}{Performance}}\label{README.md_autotoc_md35845}
For performance sensitive applications, {\ttfamily xxhash-\/wasm} provides the {\ttfamily h\texorpdfstring{$\ast$}{*}\texorpdfstring{$\ast$}{*}} and {\ttfamily h\texorpdfstring{$\ast$}{*}\texorpdfstring{$\ast$}{*}\+Raw} APIs, which return raw numeric hash results rather than zero-\/padded hex strings. The overhead of the string conversion in the {\ttfamily h\texorpdfstring{$\ast$}{*}\texorpdfstring{$\ast$}{*}\+To\+String} APIs can be as much as 20\% of overall runtime when hashing small byte-\/size inputs, and the string result is often inconsequential (for example when simply checking if the the resulting hashes are the same). When necessary, getting a zero-\/padded hex string from the provided {\ttfamily number} or \href{https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/BigInt}{\texttt{ {\ttfamily Big\+Int}}} results is easily achieved via {\ttfamily result.\+to\+String(16).pad\+Start(16, "{}0"{})} and the {\ttfamily h\texorpdfstring{$\ast$}{*}\texorpdfstring{$\ast$}{*}\+To\+String} APIs are purely for convenience.

The {\ttfamily h\texorpdfstring{$\ast$}{*}\texorpdfstring{$\ast$}{*}}, {\ttfamily h\texorpdfstring{$\ast$}{*}\texorpdfstring{$\ast$}{*}\+To\+String}, and streaming APIs make use of \href{https://developer.mozilla.org/en-US/docs/Web/API/TextEncoder/encodeInto}{\texttt{ {\ttfamily Text\+Encoder.\+encode\+Into}}} to directly encode strings as a stream of UTF-\/8 bytes into the Web\+Assembly memory buffer, meaning that for string-\/hashing purposes, these APIs will be significantly faster than converting the string to bytes externally and using the {\ttfamily Raw} API. That said, for large strings it may be beneficial to consider the streaming API or another approach to encoding, as {\ttfamily encode\+Into} is forced to allocate 3-\/times the string length to account for the chance the input string contains high-\/byte-\/count code units.

{\itshape If possible, defer the encoding of the string to the hashing, unless you need to use the encoded string (bytes) for other purposes as well, or you are creating the bytes differently (e.\+g. different encoding), in which case it\textquotesingle{}s much more efficient to use the {\ttfamily h\texorpdfstring{$\ast$}{*}\texorpdfstring{$\ast$}{*}\+Raw} APIs instead of having to unnecessarily convert them to a string first.}\hypertarget{README.md_autotoc_md35846}{}\doxysubsubsection{\texorpdfstring{Engine Requirements}{Engine Requirements}}\label{README.md_autotoc_md35846}
In an effort to make this library as performant as possible, it uses several recent additions to browsers, Node and the Web\+Assembly specification. Notably, these include\+:


\begin{DoxyEnumerate}
\item \href{https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/BigInt}{\texttt{ {\ttfamily Big\+Int}}} support in Web\+Assembly
\item Bulk memory operations in Web\+Assembly
\item \href{https://developer.mozilla.org/en-US/docs/Web/API/TextEncoder/encodeInto}{\texttt{ {\ttfamily Text\+Encoder.\+encode\+Into}}}
\end{DoxyEnumerate}

Taking all of these requirements into account, {\ttfamily xxhash-\/wasm} should be compatible with\+:


\begin{DoxyItemize}
\item Chrome \texorpdfstring{$>$}{>}= 85
\item Edge \texorpdfstring{$>$}{>}= 79
\item Firefox \texorpdfstring{$>$}{>}= 79
\item Safari \texorpdfstring{$>$}{>}= 15.\+0
\item Node \texorpdfstring{$>$}{>}= 15.\+0
\end{DoxyItemize}

If support for an older engine is required, {\ttfamily xxhash-\/wasm@0.\+4.\+2} is available with much broader engine support, but 3-\/4x slower hashing performance.\hypertarget{README.md_autotoc_md35847}{}\doxysubsection{\texorpdfstring{API}{API}}\label{README.md_autotoc_md35847}

\begin{DoxyCode}{0}
\DoxyCodeLine{const\ \{}
\DoxyCodeLine{\ \ h32,}
\DoxyCodeLine{\ \ h32ToString,}
\DoxyCodeLine{\ \ h32Raw,}
\DoxyCodeLine{\ \ create32,}
\DoxyCodeLine{\ \ h64,}
\DoxyCodeLine{\ \ h64ToString,}
\DoxyCodeLine{\ \ h64Raw,}
\DoxyCodeLine{\ \ create64,}
\DoxyCodeLine{\}\ =\ await\ xxhash();}

\end{DoxyCode}


Create a Web\+Assembly instance.\hypertarget{README.md_autotoc_md35848}{}\doxysubsubsection{\texorpdfstring{h32}{h32}}\label{README.md_autotoc_md35848}

\begin{DoxyCode}{0}
\DoxyCodeLine{h32(input:\ string,\ [seed:\ u32]):\ number}

\end{DoxyCode}


Generate a 32-\/bit hash of the UTF-\/8 encoded bytes of {\ttfamily input}. The optional {\ttfamily seed} is a {\ttfamily \doxylink{circom_8hpp_afaa62991928fb9fb18ff0db62a040aba}{u32}} and any number greater than the maximum ({\ttfamily 0xffffffff}) is wrapped, which means that {\ttfamily 0xffffffff + 1 = 0}.

Returns a {\ttfamily \doxylink{circom_8hpp_afaa62991928fb9fb18ff0db62a040aba}{u32}} {\ttfamily number} containing the hash value.


\begin{DoxyCode}{0}
\DoxyCodeLine{h32ToString(input:\ string,\ [seed:\ u32]):\ string}

\end{DoxyCode}


Same as {\ttfamily h32}, but returning a zero-\/padded hex string.


\begin{DoxyCode}{0}
\DoxyCodeLine{h32Raw(input:\ Uint8Array,\ [seed:\ u32]):\ number}

\end{DoxyCode}


Same as {\ttfamily h32} but with a {\ttfamily Uint8\+Array} as input instead of a {\ttfamily string}.\hypertarget{README.md_autotoc_md35849}{}\doxysubsubsection{\texorpdfstring{h64}{h64}}\label{README.md_autotoc_md35849}

\begin{DoxyCode}{0}
\DoxyCodeLine{h64(input:\ string,\ [seed:\ bigint]):\ bigint}

\end{DoxyCode}


Generate a 64-\/bit hash of the UTF-\/8 encoded bytes of {\ttfamily input}. The optional {\ttfamily seed} is a {\ttfamily \doxylink{circom_8hpp_ad758b7a5c3f18ed79d2fcd23d9f16357}{u64}} provided as a \href{https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/BigInt}{\texttt{ Big\+Int}}.

Returns a {\ttfamily \doxylink{circom_8hpp_ad758b7a5c3f18ed79d2fcd23d9f16357}{u64}} {\ttfamily bigint} containing the hash value.


\begin{DoxyCode}{0}
\DoxyCodeLine{h64ToString(input:\ string,\ [seed:\ bigint]):\ string}

\end{DoxyCode}


Same as {\ttfamily h64}, but returning a zero-\/padded hex string.


\begin{DoxyCode}{0}
\DoxyCodeLine{h64Raw(input:\ Uint8Array,\ [seed:\ bigint]):\ bigint}

\end{DoxyCode}


Same as {\ttfamily h64} but with a {\ttfamily Uint8\+Array} as input instead of a {\ttfamily string}.\hypertarget{README.md_autotoc_md35850}{}\doxysubsubsection{\texorpdfstring{Streaming}{Streaming}}\label{README.md_autotoc_md35850}

\begin{DoxyCode}{0}
\DoxyCodeLine{type\ XXHash<T>\ \{}
\DoxyCodeLine{\ \ update(input:\ string\ |\ Uint8Array):\ XXHash<T>;}
\DoxyCodeLine{\ \ digest():\ T}
\DoxyCodeLine{\}}

\end{DoxyCode}


The streaming API mirrors Node\textquotesingle{}s built-\/in {\ttfamily crypto.\+create\+Hash}, providing {\ttfamily update} and {\ttfamily digest} methods to add data to the hash and compute the final hash value, respectively.


\begin{DoxyCode}{0}
\DoxyCodeLine{create32([seed:\ number]):\ XXHash<number>}

\end{DoxyCode}


Create a 32-\/bit hash for streaming applications.


\begin{DoxyCode}{0}
\DoxyCodeLine{create64([seed:\ bigint]):\ XXHash<bigint>}

\end{DoxyCode}


Create a 64-\/bit hash for streaming applications.\hypertarget{README.md_autotoc_md35851}{}\doxysubsection{\texorpdfstring{Comparison to \href{https://github.com/pierrec/js-xxhash}{\texttt{ xxhashjs}}}{Comparison to \href{https://github.com/pierrec/js-xxhash}{\texttt{ xxhashjs}}}}\label{README.md_autotoc_md35851}
\href{https://github.com/pierrec/js-xxhash}{\texttt{ {\ttfamily xxhashjs}}} is implemented in pure Java\+Script and because Java\+Script is lacking support for 64-\/bit integers, it uses a workaround with \href{https://github.com/pierrec/js-cuint}{\texttt{ {\ttfamily cuint}}}. Not only is that a big performance hit, but it also increases the bundle size by quite a bit when it\textquotesingle{}s used in the browser.

This library ({\ttfamily xxhash-\/wasm}) has the big advantage that Web\+Assembly supports {\ttfamily \doxylink{circom_8hpp_ad758b7a5c3f18ed79d2fcd23d9f16357}{u64}} and also some instructions (e.\+g. {\ttfamily rotl}), which would otherwise have to be emulated. However, The downside is that you have to initialise a Web\+Assembly instance, which takes a little over 2ms in Node and about 1ms in the browser. But once the instance is created, it can be used without any further overhead. For the benchmarks below, the instantiation is done before the benchmark and therefore it\textquotesingle{}s excluded from the results, since it wouldn\textquotesingle{}t make sense to always create a new Web\+Assembly instance.\hypertarget{README.md_autotoc_md35852}{}\doxysubsubsection{\texorpdfstring{Benchmarks}{Benchmarks}}\label{README.md_autotoc_md35852}
Benchmarks are using \href{https://benchmarkjs.com/}{\texttt{ Benchmark.\+js}} with random strings of different lengths. {\itshape Higher is better}

\tabulinesep=1mm
\begin{longtabu}spread 0pt [c]{*{5}{|X[-1]}|}
\hline
\PBS\raggedleft \cellcolor{\tableheadbgcolor}\textbf{ String length   }&\PBS\centering \cellcolor{\tableheadbgcolor}\textbf{ xxhashjs 32-\/bit   }&\PBS\centering \cellcolor{\tableheadbgcolor}\textbf{ xxhashjs 64-\/bit   }&\PBS\centering \cellcolor{\tableheadbgcolor}\textbf{ xxhash-\/wasm 32-\/bit   }&\PBS\centering \cellcolor{\tableheadbgcolor}\textbf{ xxhash-\/wasm 64-\/bit    }\\\cline{1-5}
\endfirsthead
\hline
\endfoot
\hline
\PBS\raggedleft \cellcolor{\tableheadbgcolor}\textbf{ String length   }&\PBS\centering \cellcolor{\tableheadbgcolor}\textbf{ xxhashjs 32-\/bit   }&\PBS\centering \cellcolor{\tableheadbgcolor}\textbf{ xxhashjs 64-\/bit   }&\PBS\centering \cellcolor{\tableheadbgcolor}\textbf{ xxhash-\/wasm 32-\/bit   }&\PBS\centering \cellcolor{\tableheadbgcolor}\textbf{ xxhash-\/wasm 64-\/bit    }\\\cline{1-5}
\endhead
\PBS\raggedleft 1 byte   &513,517 ops/sec   &11,896 ops/sec   &{\itshape {\bfseries{5,752,446 ops/sec}}}   &4,438,501 ops/sec    \\\cline{1-5}
\PBS\raggedleft 10 bytes   &552,133 ops/sec   &12,953 ops/sec   &{\itshape {\bfseries{6,240,640 ops/sec}}}   &4,855,340 ops/sec    \\\cline{1-5}
\PBS\raggedleft 100 bytes   &425,277 ops/sec   &10,838 ops/sec   &{\itshape {\bfseries{5,470,011 ops/sec}}}   &4,314,904 ops/sec    \\\cline{1-5}
\PBS\raggedleft 1,000 bytes   &102,165 ops/sec   &6,697 ops/sec   &3,283,526 ops/sec   &{\itshape {\bfseries{3,332,556 ops/sec}}}    \\\cline{1-5}
\PBS\raggedleft 10,000 bytes   &13,010 ops/sec   &1,452 ops/sec   &589,068 ops/sec   &{\itshape {\bfseries{940,350 ops/sec}}}    \\\cline{1-5}
\PBS\raggedleft 100,000 bytes   &477 ops/sec   &146 ops/sec   &61,824 ops/sec   &{\itshape {\bfseries{98,959 ops/sec}}}    \\\cline{1-5}
\PBS\raggedleft 1,000,000 bytes   &36.\+40 ops/sec   &12.\+93 ops/sec   &5,122 ops/sec   &{\itshape {\bfseries{8,632 ops/sec}}}    \\\cline{1-5}
\PBS\raggedleft 10,000,000 bytes   &3.\+12 ops/sec   &1.\+19 ops/sec   &326 ops/sec   &{\itshape {\bfseries{444 ops/sec}}}    \\\cline{1-5}
\PBS\raggedleft 100,000,000 bytes   &0.\+31 ops/sec   &0.\+13 ops/sec   &27.\+84 ops/sec   &{\itshape {\bfseries{34.\+56 ops/sec}}}   \\\cline{1-5}
\end{longtabu}


{\ttfamily xxhash-\/wasm} outperforms {\ttfamily xxhashjs} significantly, the 32-\/bit is up to 90 times faster (generally increases as the size of the input grows), and the 64-\/bit is up to 350 times faster (generally increases as the size of the input grows).

The 64-\/bit version is the faster algorithm but there is a small degree of overhead involved in using Big\+Ints, and so it retains a performance advantage over all lengths over xxhashjs and the 32-\/bit algorithm above \texorpdfstring{$\sim$}{\string~}1000 bytes.

{\ttfamily xxhash-\/wasm} also significantly outperforms Node\textquotesingle{}s built-\/in hash algorithms, making it suitable for use in a wide variety of situations, where non-\/cryptographic hashes are acceptable. Benchmarks from an x64 Mac\+Book Pro running Node 17.\+3\+:

\tabulinesep=1mm
\begin{longtabu}spread 0pt [c]{*{4}{|X[-1]}|}
\hline
\PBS\raggedleft \cellcolor{\tableheadbgcolor}\textbf{ String length   }&\PBS\centering \cellcolor{\tableheadbgcolor}\textbf{ Node {\ttfamily crypto} md5   }&\PBS\centering \cellcolor{\tableheadbgcolor}\textbf{ Node {\ttfamily crypto} sha1   }&\PBS\centering \cellcolor{\tableheadbgcolor}\textbf{ xxhash-\/wasm 64-\/bit    }\\\cline{1-4}
\endfirsthead
\hline
\endfoot
\hline
\PBS\raggedleft \cellcolor{\tableheadbgcolor}\textbf{ String length   }&\PBS\centering \cellcolor{\tableheadbgcolor}\textbf{ Node {\ttfamily crypto} md5   }&\PBS\centering \cellcolor{\tableheadbgcolor}\textbf{ Node {\ttfamily crypto} sha1   }&\PBS\centering \cellcolor{\tableheadbgcolor}\textbf{ xxhash-\/wasm 64-\/bit    }\\\cline{1-4}
\endhead
\PBS\raggedleft 1 byte   &342,924 ops/sec   &352,825 ops/sec   &{\itshape {\bfseries{4,438,501 ops/sec}}}    \\\cline{1-4}
\PBS\raggedleft 10 bytes   &356,596 ops/sec   &352,209 ops/sec   &{\itshape {\bfseries{4,855,340 ops/sec}}}    \\\cline{1-4}
\PBS\raggedleft 100 bytes   &354,898 ops/sec   &355,024 ops/sec   &{\itshape {\bfseries{4,314,904 ops/sec}}}    \\\cline{1-4}
\PBS\raggedleft 1,000 bytes   &249,242 ops/sec   &271,383 ops/sec   &{\itshape {\bfseries{3,332,556 ops/sec}}}    \\\cline{1-4}
\PBS\raggedleft 10,000 bytes   &62,896 ops/sec   &80,986 ops/sec   &{\itshape {\bfseries{940,350 ops/sec}}}    \\\cline{1-4}
\PBS\raggedleft 100,000 bytes   &7,316 ops/sec   &10,198 ops/sec   &{\itshape {\bfseries{98,959 ops/sec}}}    \\\cline{1-4}
\PBS\raggedleft 1,000,000 bytes   &698 ops/sec   &966 ops/sec   &{\itshape {\bfseries{8,632 ops/sec}}}    \\\cline{1-4}
\PBS\raggedleft 10,000,000 bytes   &58.\+98 ops/sec   &79.\+78 ops/sec   &{\itshape {\bfseries{444 ops/sec}}}    \\\cline{1-4}
\PBS\raggedleft 100,000,000 bytes   &6.\+30 ops/sec   &8.\+20 ops/sec   &{\itshape {\bfseries{34.\+56 ops/sec}}}   \\\cline{1-4}
\end{longtabu}


If suitable for your use case, the {\ttfamily Raw} API offers significant throughput improvements over the string-\/hashing API, particularly for smaller inputs, assuming that you have access to the {\ttfamily Uint8\+Array} already (see also the Performance section)\+:

\tabulinesep=1mm
\begin{longtabu}spread 0pt [c]{*{3}{|X[-1]}|}
\hline
\PBS\raggedleft \cellcolor{\tableheadbgcolor}\textbf{ String length   }&\PBS\centering \cellcolor{\tableheadbgcolor}\textbf{ xxhash-\/wasm 64-\/bit Raw   }&\PBS\centering \cellcolor{\tableheadbgcolor}\textbf{ xxhash-\/wasm 64-\/bit    }\\\cline{1-3}
\endfirsthead
\hline
\endfoot
\hline
\PBS\raggedleft \cellcolor{\tableheadbgcolor}\textbf{ String length   }&\PBS\centering \cellcolor{\tableheadbgcolor}\textbf{ xxhash-\/wasm 64-\/bit Raw   }&\PBS\centering \cellcolor{\tableheadbgcolor}\textbf{ xxhash-\/wasm 64-\/bit    }\\\cline{1-3}
\endhead
\PBS\raggedleft 1 byte   &{\itshape {\bfseries{9,342,811 ops/sec}}}   &4,438,501 ops/sec    \\\cline{1-3}
\PBS\raggedleft 10 bytes   &{\itshape {\bfseries{9,668,989 ops/sec}}}   &4,855,340 ops/sec    \\\cline{1-3}
\PBS\raggedleft 100 bytes   &{\itshape {\bfseries{8,775,845 ops/sec}}}   &4,314,904 ops/sec    \\\cline{1-3}
\PBS\raggedleft 1,000 bytes   &{\itshape {\bfseries{5,541,403 ops/sec}}}   &3,332,556 ops/sec    \\\cline{1-3}
\PBS\raggedleft 10,000 bytes   &{\itshape {\bfseries{1,079,866 ops/sec}}}   &940,350 ops/sec    \\\cline{1-3}
\PBS\raggedleft 100,000 bytes   &{\itshape {\bfseries{113,350 ops/sec}}}   &98,959 ops/sec    \\\cline{1-3}
\PBS\raggedleft 1,000,000 bytes   &{\itshape {\bfseries{9,779 ops/sec}}}   &8,632 ops/sec    \\\cline{1-3}
\PBS\raggedleft 10,000,000 bytes   &{\itshape {\bfseries{563 ops/sec}}}   &444 ops/sec    \\\cline{1-3}
\PBS\raggedleft 100,000,000 bytes   &{\itshape {\bfseries{43.\+77 ops/sec}}}   &34.\+56 ops/sec   \\\cline{1-3}
\end{longtabu}
\hypertarget{README.md_autotoc_md35853}{}\doxysubsubsection{\texorpdfstring{Bundle size}{Bundle size}}\label{README.md_autotoc_md35853}
Both libraries can be used in the browser and they provide a UMD bundle. The bundles are self-\/contained, that means they can be included and used without having to add any other dependencies. The table shows the bundle size of the minified versions. {\itshape Lower is better}.

\tabulinesep=1mm
\begin{longtabu}spread 0pt [c]{*{3}{|X[-1]}|}
\hline
\PBS\centering \cellcolor{\tableheadbgcolor}\textbf{ }&\PBS\centering \cellcolor{\tableheadbgcolor}\textbf{ xxhashjs   }&\PBS\centering \cellcolor{\tableheadbgcolor}\textbf{ xxhash-\/wasm    }\\\cline{1-3}
\endfirsthead
\hline
\endfoot
\hline
\PBS\centering \cellcolor{\tableheadbgcolor}\textbf{ }&\PBS\centering \cellcolor{\tableheadbgcolor}\textbf{ xxhashjs   }&\PBS\centering \cellcolor{\tableheadbgcolor}\textbf{ xxhash-\/wasm    }\\\cline{1-3}
\endhead
Bundle size   &41.\+5kB   &{\itshape {\bfseries{11.\+4kB}}}    \\\cline{1-3}
Gzipped Size   &10.\+3kB   &{\itshape {\bfseries{2.\+3kB}}}   \\\cline{1-3}
\end{longtabu}
