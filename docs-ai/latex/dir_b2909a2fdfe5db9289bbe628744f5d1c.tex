\doxysection{src/lib/ai Directory Reference}
\hypertarget{dir_b2909a2fdfe5db9289bbe628744f5d1c}{}\label{dir_b2909a2fdfe5db9289bbe628744f5d1c}\index{src/lib/ai Directory Reference@{src/lib/ai Directory Reference}}
\doxysubsubsection*{Directories}
\begin{DoxyCompactItemize}
\item 
directory \mbox{\hyperlink{dir_4736f6c5f583938e3d84c034d4281ac5}{mental-\/arena}}
\item 
directory \mbox{\hyperlink{dir_110183797cf1009d70eebe8f13d9b8d4}{mental-\/llama}}
\item 
directory \mbox{\hyperlink{dir_bf9f6ea2b0d861aa068a88f8ba01b82f}{providers}}
\end{DoxyCompactItemize}


\doxysubsection{Detailed Description}
This module provides a comprehensive set of tools for integrating AI capabilities into the application. It includes services for sentiment analysis, crisis detection, response generation, and intervention analysis, as well as utilities for error handling and performance optimization.\hypertarget{README.md_autotoc_md37426}{}\doxysubsection{\texorpdfstring{Table of Contents}{Table of Contents}}\label{README.md_autotoc_md37426}

\begin{DoxyItemize}
\item \doxylink{md_node__modules_2safer-buffer_2_porting-_buffer_overview}{Overview}
\item Services
\item Error Handling
\item Performance Optimization
\item Usage Examples
\item API Reference
\end{DoxyItemize}\hypertarget{README.md_autotoc_md37427}{}\doxysubsection{\texorpdfstring{Overview}{Overview}}\label{README.md_autotoc_md37427}
The AI module is designed to provide a unified interface for interacting with various AI providers, including Open\+AI and Anthropic. It abstracts away the details of the underlying APIs and provides a consistent interface for all AI-\/related functionality.

Key features include\+:


\begin{DoxyItemize}
\item Support for multiple AI providers (Open\+AI, Anthropic)
\item Specialized services for common AI tasks
\item Comprehensive error handling
\item Performance optimization with caching and metrics
\item HIPAA-\/compliant audit logging
\end{DoxyItemize}\hypertarget{README.md_autotoc_md37428}{}\doxysubsection{\texorpdfstring{Services}{Services}}\label{README.md_autotoc_md37428}
\hypertarget{README.md_autotoc_md37429}{}\doxysubsubsection{\texorpdfstring{AI Service Factory}{AI Service Factory}}\label{README.md_autotoc_md37429}
The {\ttfamily create\+AIService} function creates an AI service with the specified provider and options. It automatically applies error handling and performance optimization wrappers.


\begin{DoxyCode}{0}
\DoxyCodeLine{import\ \{\ createAIService\ \}\ from\ '../lib/ai'}
\DoxyCodeLine{}
\DoxyCodeLine{const\ aiService\ =\ createAIService(\{}
\DoxyCodeLine{\ \ provider:\ 'openai',\ //\ or\ 'anthropic'}
\DoxyCodeLine{\ \ enableErrorHandling:\ true,}
\DoxyCodeLine{\ \ enablePerformanceOptimization:\ true}
\DoxyCodeLine{\})}

\end{DoxyCode}
\hypertarget{README.md_autotoc_md37430}{}\doxysubsubsection{\texorpdfstring{Sentiment Analysis}{Sentiment Analysis}}\label{README.md_autotoc_md37430}
The {\ttfamily Sentiment\+Analysis\+Service} analyzes the sentiment of text, providing a score and explanation.


\begin{DoxyCode}{0}
\DoxyCodeLine{import\ \{\ createAIService,\ SentimentAnalysisService\ \}\ from\ '../lib/ai'}
\DoxyCodeLine{}
\DoxyCodeLine{const\ aiService\ =\ createAIService()}
\DoxyCodeLine{const\ sentimentService\ =\ new\ SentimentAnalysisService(\{\ aiService\ \})}
\DoxyCodeLine{}
\DoxyCodeLine{const\ result\ =\ await\ sentimentService.analyzeSentiment('I\ am\ feeling\ great\ today!')}
\DoxyCodeLine{//\ \{\ sentiment:\ 'positive',\ score:\ 0.85,\ explanation:\ '...',\ model:\ '...',\ processingTime:\ 123\ \}}

\end{DoxyCode}
\hypertarget{README.md_autotoc_md37431}{}\doxysubsubsection{\texorpdfstring{Crisis Detection}{Crisis Detection}}\label{README.md_autotoc_md37431}
The {\ttfamily Crisis\+Detection\+Service} detects potential crisis situations in text, providing a risk level and explanation.


\begin{DoxyCode}{0}
\DoxyCodeLine{import\ \{\ createAIService,\ CrisisDetectionService\ \}\ from\ '../lib/ai'}
\DoxyCodeLine{}
\DoxyCodeLine{const\ aiService\ =\ createAIService()}
\DoxyCodeLine{const\ crisisService\ =\ new\ CrisisDetectionService(\{\ aiService\ \})}
\DoxyCodeLine{}
\DoxyCodeLine{const\ result\ =\ await\ crisisService.detectCrisis('I\ am\ feeling\ really\ down\ lately.')}
\DoxyCodeLine{//\ \{\ is\_crisis:\ true,\ risk\_level:\ 'low',\ crisis\_type:\ 'depression',\ confidence:\ 0.65,\ ...\ \}}

\end{DoxyCode}
\hypertarget{README.md_autotoc_md37432}{}\doxysubsubsection{\texorpdfstring{Response Generation}{Response Generation}}\label{README.md_autotoc_md37432}
The {\ttfamily Response\+Generation\+Service} generates responses to user messages, with support for streaming.


\begin{DoxyCode}{0}
\DoxyCodeLine{import\ \{\ createAIService,\ ResponseGenerationService\ \}\ from\ '../lib/ai'}
\DoxyCodeLine{}
\DoxyCodeLine{const\ aiService\ =\ createAIService()}
\DoxyCodeLine{const\ responseService\ =\ new\ ResponseGenerationService(\{\ aiService\ \})}
\DoxyCodeLine{}
\DoxyCodeLine{const\ result\ =\ await\ responseService.generateResponse([}
\DoxyCodeLine{\ \ \{\ role:\ 'user',\ content:\ 'Hello,\ how\ are\ you?'\ \}}
\DoxyCodeLine{])}
\DoxyCodeLine{//\ \{\ response:\ 'I\ am\ doing\ well,\ thank\ you!',\ model:\ '...',\ processingTime:\ 123\ \}}

\end{DoxyCode}
\hypertarget{README.md_autotoc_md37433}{}\doxysubsubsection{\texorpdfstring{Intervention Analysis}{Intervention Analysis}}\label{README.md_autotoc_md37433}
The {\ttfamily Intervention\+Analysis\+Service} analyzes the effectiveness of therapeutic interventions.


\begin{DoxyCode}{0}
\DoxyCodeLine{import\ \{\ createAIService,\ InterventionAnalysisService\ \}\ from\ '../lib/ai'}
\DoxyCodeLine{}
\DoxyCodeLine{const\ aiService\ =\ createAIService()}
\DoxyCodeLine{const\ interventionService\ =\ new\ InterventionAnalysisService(\{\ aiService\ \})}
\DoxyCodeLine{}
\DoxyCodeLine{const\ result\ =\ await\ interventionService.analyzeIntervention(}
\DoxyCodeLine{\ \ conversation,}
\DoxyCodeLine{\ \ interventionMessage,}
\DoxyCodeLine{\ \ userResponse}
\DoxyCodeLine{)}
\DoxyCodeLine{//\ \{\ effectiveness\_score:\ 8,\ user\_receptiveness:\ 'high',\ emotional\_impact:\ 'positive',\ ...\ \}}

\end{DoxyCode}
\hypertarget{README.md_autotoc_md37434}{}\doxysubsection{\texorpdfstring{Error Handling}{Error Handling}}\label{README.md_autotoc_md37434}
The AI module includes a comprehensive error handling system that standardizes errors across different providers and provides detailed error information.\hypertarget{README.md_autotoc_md37435}{}\doxysubsubsection{\texorpdfstring{AIError Class}{AIError Class}}\label{README.md_autotoc_md37435}
The {\ttfamily AIError} class is a custom error class for AI-\/related errors. It includes a code, status code, context, and original error.


\begin{DoxyCode}{0}
\DoxyCodeLine{import\ \{\ AIError,\ AIErrorCodes\ \}\ from\ '../lib/ai'}
\DoxyCodeLine{}
\DoxyCodeLine{throw\ new\ AIError('The\ AI\ service\ is\ currently\ unavailable',\ \{}
\DoxyCodeLine{\ \ code:\ AIErrorCodes.SERVICE\_UNAVAILABLE,}
\DoxyCodeLine{\ \ statusCode:\ 503,}
\DoxyCodeLine{\ \ context:\ \{\ model:\ 'gpt-\/4o'\ \}}
\DoxyCodeLine{\})}

\end{DoxyCode}
\hypertarget{README.md_autotoc_md37436}{}\doxysubsubsection{\texorpdfstring{Error Handling Utilities}{Error Handling Utilities}}\label{README.md_autotoc_md37436}
The module includes utilities for handling errors from AI services and transforming them into standardized AIErrors.


\begin{DoxyCode}{0}
\DoxyCodeLine{import\ \{\ AIErrorCodes,\ handleAIServiceError\ \}\ from\ '../lib/ai'}
\DoxyCodeLine{}
\DoxyCodeLine{try\ \{}
\DoxyCodeLine{\ \ //\ Call\ AI\ service}
\DoxyCodeLine{\}}
\DoxyCodeLine{catch\ (error)\ \{}
\DoxyCodeLine{\ \ const\ aiError\ =\ handleAIServiceError(error,\ \{\ model:\ 'gpt-\/4o'\ \})}
\DoxyCodeLine{\ \ console.error(`AI\ Error:\ \$\{aiError.message\}\ (\$\{aiError.code\})`)}
\DoxyCodeLine{\}}

\end{DoxyCode}
\hypertarget{README.md_autotoc_md37437}{}\doxysubsubsection{\texorpdfstring{API Error Handling}{API Error Handling}}\label{README.md_autotoc_md37437}
The module includes a utility for handling errors in API routes and returning appropriate responses.


\begin{DoxyCode}{0}
\DoxyCodeLine{import\ \{\ handleApiError\ \}\ from\ '../lib/ai'}
\DoxyCodeLine{}
\DoxyCodeLine{try\ \{}
\DoxyCodeLine{\ \ //\ API\ route\ logic}
\DoxyCodeLine{\}}
\DoxyCodeLine{catch\ (error)\ \{}
\DoxyCodeLine{\ \ return\ handleApiError(error)}
\DoxyCodeLine{\}}

\end{DoxyCode}
\hypertarget{README.md_autotoc_md37438}{}\doxysubsection{\texorpdfstring{Performance Optimization}{Performance Optimization}}\label{README.md_autotoc_md37438}
The AI module includes utilities for optimizing the performance of AI services, including caching and metrics collection.\hypertarget{README.md_autotoc_md37439}{}\doxysubsubsection{\texorpdfstring{Optimized AI Service}{Optimized AI Service}}\label{README.md_autotoc_md37439}
The {\ttfamily create\+Optimized\+AIService} function creates a performance-\/optimized AI service wrapper.


\begin{DoxyCode}{0}
\DoxyCodeLine{import\ \{\ createOptimizedAIService\ \}\ from\ '../lib/ai'}
\DoxyCodeLine{}
\DoxyCodeLine{const\ optimizedService\ =\ createOptimizedAIService(aiService,\ \{}
\DoxyCodeLine{\ \ logToConsole:\ true,}
\DoxyCodeLine{\ \ createAuditLogs:\ true,}
\DoxyCodeLine{\ \ slowRequestThreshold:\ 3000,}
\DoxyCodeLine{\ \ highTokenUsageThreshold:\ 1000}
\DoxyCodeLine{\})}

\end{DoxyCode}
\hypertarget{README.md_autotoc_md37440}{}\doxysubsubsection{\texorpdfstring{Token Usage Optimization}{Token Usage Optimization}}\label{README.md_autotoc_md37440}
The module includes utilities for estimating token usage and truncating messages to fit within token limits.


\begin{DoxyCode}{0}
\DoxyCodeLine{import\ \{\ estimateMessagesTokenCount,\ truncateMessages\ \}\ from\ '../lib/ai'}
\DoxyCodeLine{}
\DoxyCodeLine{const\ tokenCount\ =\ estimateMessagesTokenCount(messages)}
\DoxyCodeLine{console.log(`Estimated\ token\ count:\ \$\{tokenCount\}`)}
\DoxyCodeLine{}
\DoxyCodeLine{const\ truncatedMessages\ =\ truncateMessages(messages,\ 4000,\ 1000)}

\end{DoxyCode}
\hypertarget{README.md_autotoc_md37441}{}\doxysubsection{\texorpdfstring{Usage Examples}{Usage Examples}}\label{README.md_autotoc_md37441}
\hypertarget{README.md_autotoc_md37442}{}\doxysubsubsection{\texorpdfstring{Basic Usage}{Basic Usage}}\label{README.md_autotoc_md37442}

\begin{DoxyCode}{0}
\DoxyCodeLine{import\ \{\ createAIService\ \}\ from\ '../lib/ai'}
\DoxyCodeLine{}
\DoxyCodeLine{const\ aiService\ =\ createAIService()}
\DoxyCodeLine{}
\DoxyCodeLine{const\ completion\ =\ await\ aiService.createChatCompletion(}
\DoxyCodeLine{\ \ [\{\ role:\ 'user',\ content:\ 'Hello,\ how\ are\ you?'\ \}],}
\DoxyCodeLine{\ \ \{\ model:\ 'gpt-\/4o'\ \}}
\DoxyCodeLine{)}
\DoxyCodeLine{}
\DoxyCodeLine{console.log(completion.content)}

\end{DoxyCode}
\hypertarget{README.md_autotoc_md37443}{}\doxysubsubsection{\texorpdfstring{Streaming Response}{Streaming Response}}\label{README.md_autotoc_md37443}

\begin{DoxyCode}{0}
\DoxyCodeLine{import\ \{\ createAIService\ \}\ from\ '../lib/ai'}
\DoxyCodeLine{}
\DoxyCodeLine{const\ aiService\ =\ createAIService()}
\DoxyCodeLine{}
\DoxyCodeLine{const\ \{\ stream\ \}\ =\ await\ aiService.createStreamingChatCompletion(}
\DoxyCodeLine{\ \ [\{\ role:\ 'user',\ content:\ 'Hello,\ how\ are\ you?'\ \}],}
\DoxyCodeLine{\ \ \{\ model:\ 'gpt-\/4o'\ \}}
\DoxyCodeLine{)}
\DoxyCodeLine{}
\DoxyCodeLine{for\ await\ (const\ chunk\ of\ stream)\ \{}
\DoxyCodeLine{\ \ process.stdout.write(chunk.content)}
\DoxyCodeLine{\}}

\end{DoxyCode}
\hypertarget{README.md_autotoc_md37444}{}\doxysubsubsection{\texorpdfstring{Error Handling}{Error Handling}}\label{README.md_autotoc_md37444}

\begin{DoxyCode}{0}
\DoxyCodeLine{import\ \{\ AIError,\ AIErrorCodes,\ createAIService\ \}\ from\ '../lib/ai'}
\DoxyCodeLine{}
\DoxyCodeLine{const\ aiService\ =\ createAIService()}
\DoxyCodeLine{}
\DoxyCodeLine{try\ \{}
\DoxyCodeLine{\ \ const\ completion\ =\ await\ aiService.createChatCompletion(}
\DoxyCodeLine{\ \ \ \ [\{\ role:\ 'user',\ content:\ 'Hello,\ how\ are\ you?'\ \}],}
\DoxyCodeLine{\ \ \ \ \{\ model:\ 'invalid-\/model'\ \}}
\DoxyCodeLine{\ \ )}
\DoxyCodeLine{\}}
\DoxyCodeLine{catch\ (error)\ \{}
\DoxyCodeLine{\ \ if\ (error\ instanceof\ AIError\ \&\&\ error.code\ ===\ AIErrorCodes.INVALID\_MODEL)\ \{}
\DoxyCodeLine{\ \ \ \ console.error('Invalid\ model\ specified')}
\DoxyCodeLine{\ \ \}}
\DoxyCodeLine{\ \ else\ \{}
\DoxyCodeLine{\ \ \ \ console.error('An\ unexpected\ error\ occurred:',\ error)}
\DoxyCodeLine{\ \ \}}
\DoxyCodeLine{\}}

\end{DoxyCode}
\hypertarget{README.md_autotoc_md37445}{}\doxysubsubsection{\texorpdfstring{Retry with Exponential Backoff}{Retry with Exponential Backoff}}\label{README.md_autotoc_md37445}

\begin{DoxyCode}{0}
\DoxyCodeLine{import\ \{\ createAIService,\ withRetry\ \}\ from\ '../lib/ai'}
\DoxyCodeLine{}
\DoxyCodeLine{const\ aiService\ =\ createAIService()}
\DoxyCodeLine{}
\DoxyCodeLine{const\ completion\ =\ await\ withRetry(}
\DoxyCodeLine{\ \ ()\ =>\ aiService.createChatCompletion(}
\DoxyCodeLine{\ \ \ \ [\{\ role:\ 'user',\ content:\ 'Hello,\ how\ are\ you?'\ \}],}
\DoxyCodeLine{\ \ \ \ \{\ model:\ 'gpt-\/4o'\ \}}
\DoxyCodeLine{\ \ ),}
\DoxyCodeLine{\ \ \{}
\DoxyCodeLine{\ \ \ \ maxRetries:\ 3,}
\DoxyCodeLine{\ \ \ \ initialDelay:\ 500,}
\DoxyCodeLine{\ \ \ \ maxDelay:\ 10000,}
\DoxyCodeLine{\ \ \ \ factor:\ 2}
\DoxyCodeLine{\ \ \}}
\DoxyCodeLine{)}

\end{DoxyCode}
\hypertarget{README.md_autotoc_md37446}{}\doxysubsection{\texorpdfstring{API Reference}{API Reference}}\label{README.md_autotoc_md37446}
\hypertarget{README.md_autotoc_md37447}{}\doxysubsubsection{\texorpdfstring{AI Service}{AI Service}}\label{README.md_autotoc_md37447}

\begin{DoxyCode}{0}
\DoxyCodeLine{interface\ AIService\ \{}
\DoxyCodeLine{\ \ createChatCompletion:\ (}
\DoxyCodeLine{\ \ \ \ messages:\ AIMessage[],}
\DoxyCodeLine{\ \ \ \ options?:\ AIServiceOptions}
\DoxyCodeLine{\ \ )\ =>\ Promise<AICompletion>}
\DoxyCodeLine{}
\DoxyCodeLine{\ \ createStreamingChatCompletion:\ (}
\DoxyCodeLine{\ \ \ \ messages:\ AIMessage[],}
\DoxyCodeLine{\ \ \ \ options?:\ AIServiceOptions}
\DoxyCodeLine{\ \ )\ =>\ Promise<AIStreamingCompletion>}
\DoxyCodeLine{}
\DoxyCodeLine{\ \ getModelInfo:\ (model:\ string)\ =>\ ModelInfo}
\DoxyCodeLine{\}}

\end{DoxyCode}
\hypertarget{README.md_autotoc_md37448}{}\doxysubsubsection{\texorpdfstring{AI Message}{AI Message}}\label{README.md_autotoc_md37448}

\begin{DoxyCode}{0}
\DoxyCodeLine{interface\ AIMessage\ \{}
\DoxyCodeLine{\ \ role:\ 'system'\ |\ 'user'\ |\ 'assistant'}
\DoxyCodeLine{\ \ content:\ string}
\DoxyCodeLine{\}}

\end{DoxyCode}
\hypertarget{README.md_autotoc_md37449}{}\doxysubsubsection{\texorpdfstring{AI Completion}{AI Completion}}\label{README.md_autotoc_md37449}

\begin{DoxyCode}{0}
\DoxyCodeLine{interface\ AICompletion\ \{}
\DoxyCodeLine{\ \ content:\ string}
\DoxyCodeLine{\ \ model:\ string}
\DoxyCodeLine{\ \ usage?:\ \{}
\DoxyCodeLine{\ \ \ \ prompt\_tokens:\ number}
\DoxyCodeLine{\ \ \ \ completion\_tokens:\ number}
\DoxyCodeLine{\ \ \ \ total\_tokens:\ number}
\DoxyCodeLine{\ \ \}}
\DoxyCodeLine{\}}

\end{DoxyCode}
\hypertarget{README.md_autotoc_md37450}{}\doxysubsubsection{\texorpdfstring{AI Streaming Completion}{AI Streaming Completion}}\label{README.md_autotoc_md37450}

\begin{DoxyCode}{0}
\DoxyCodeLine{interface\ AIStreamingCompletion\ \{}
\DoxyCodeLine{\ \ stream:\ AsyncIterable<\{\ content:\ string\ \}>}
\DoxyCodeLine{\ \ model:\ string}
\DoxyCodeLine{\}}

\end{DoxyCode}
\hypertarget{README.md_autotoc_md37451}{}\doxysubsubsection{\texorpdfstring{AI Service Options}{AI Service Options}}\label{README.md_autotoc_md37451}

\begin{DoxyCode}{0}
\DoxyCodeLine{interface\ AIServiceOptions\ \{}
\DoxyCodeLine{\ \ model:\ string}
\DoxyCodeLine{\ \ temperature?:\ number}
\DoxyCodeLine{\ \ max\_tokens?:\ number}
\DoxyCodeLine{\ \ top\_p?:\ number}
\DoxyCodeLine{\ \ frequency\_penalty?:\ number}
\DoxyCodeLine{\ \ presence\_penalty?:\ number}
\DoxyCodeLine{\}}

\end{DoxyCode}
\hypertarget{README.md_autotoc_md37452}{}\doxysubsubsection{\texorpdfstring{Sentiment Analysis Result}{Sentiment Analysis Result}}\label{README.md_autotoc_md37452}

\begin{DoxyCode}{0}
\DoxyCodeLine{interface\ SentimentAnalysisResult\ \{}
\DoxyCodeLine{\ \ sentiment:\ 'positive'\ |\ 'negative'\ |\ 'neutral'}
\DoxyCodeLine{\ \ score:\ number}
\DoxyCodeLine{\ \ explanation:\ string}
\DoxyCodeLine{\ \ model:\ string}
\DoxyCodeLine{\ \ processingTime:\ number}
\DoxyCodeLine{\}}

\end{DoxyCode}
\hypertarget{README.md_autotoc_md37453}{}\doxysubsubsection{\texorpdfstring{Crisis Detection Result}{Crisis Detection Result}}\label{README.md_autotoc_md37453}

\begin{DoxyCode}{0}
\DoxyCodeLine{interface\ CrisisDetectionResult\ \{}
\DoxyCodeLine{\ \ is\_crisis:\ boolean}
\DoxyCodeLine{\ \ risk\_level:\ 'high'\ |\ 'medium'\ |\ 'low'\ |\ 'none'}
\DoxyCodeLine{\ \ crisis\_type:\ string\ |\ null}
\DoxyCodeLine{\ \ confidence:\ number}
\DoxyCodeLine{\ \ reasoning:\ string}
\DoxyCodeLine{\ \ model:\ string}
\DoxyCodeLine{\ \ processingTime:\ number}
\DoxyCodeLine{\}}

\end{DoxyCode}
\hypertarget{README.md_autotoc_md37454}{}\doxysubsubsection{\texorpdfstring{Response Generation Result}{Response Generation Result}}\label{README.md_autotoc_md37454}

\begin{DoxyCode}{0}
\DoxyCodeLine{interface\ ResponseGenerationResult\ \{}
\DoxyCodeLine{\ \ response:\ string}
\DoxyCodeLine{\ \ model:\ string}
\DoxyCodeLine{\ \ processingTime:\ number}
\DoxyCodeLine{\ \ usage?:\ \{}
\DoxyCodeLine{\ \ \ \ total\_tokens:\ number}
\DoxyCodeLine{\ \ \ \ prompt\_tokens:\ number}
\DoxyCodeLine{\ \ \ \ completion\_tokens:\ number}
\DoxyCodeLine{\ \ \}}
\DoxyCodeLine{\}}

\end{DoxyCode}
\hypertarget{README.md_autotoc_md37455}{}\doxysubsubsection{\texorpdfstring{Intervention Analysis Result}{Intervention Analysis Result}}\label{README.md_autotoc_md37455}

\begin{DoxyCode}{0}
\DoxyCodeLine{interface\ InterventionEffectivenessResult\ \{}
\DoxyCodeLine{\ \ effectiveness\_score:\ number}
\DoxyCodeLine{\ \ user\_receptiveness:\ 'high'\ |\ 'medium'\ |\ 'low'}
\DoxyCodeLine{\ \ emotional\_impact:\ 'positive'\ |\ 'neutral'\ |\ 'negative'}
\DoxyCodeLine{\ \ key\_insights:\ string[]}
\DoxyCodeLine{\ \ improvement\_suggestions:\ string[]}
\DoxyCodeLine{\ \ model:\ string}
\DoxyCodeLine{\ \ processingTime:\ number}
\DoxyCodeLine{\}}

\end{DoxyCode}
\hypertarget{README.md_autotoc_md37456}{}\doxysubsection{\texorpdfstring{AI Service Library}{AI Service Library}}\label{README.md_autotoc_md37456}
This library provides a comprehensive set of tools for working with AI services in a HIPAA-\/compliant environment.\hypertarget{README.md_autotoc_md37457}{}\doxysubsubsection{\texorpdfstring{Features}{Features}}\label{README.md_autotoc_md37457}

\begin{DoxyItemize}
\item Multiple AI provider support (Open\+AI, Anthropic, Gemini, Azure Open\+AI)
\item Advanced performance optimization
\item Comprehensive error handling
\item Detailed performance tracking and analytics
\item HIPAA-\/compliant audit logging
\end{DoxyItemize}\hypertarget{README.md_autotoc_md37458}{}\doxysubsubsection{\texorpdfstring{Usage}{Usage}}\label{README.md_autotoc_md37458}
\hypertarget{README.md_autotoc_md37459}{}\doxysubsubsubsection{\texorpdfstring{Basic Usage}{Basic Usage}}\label{README.md_autotoc_md37459}

\begin{DoxyCode}{0}
\DoxyCodeLine{import\ \{\ createAIService\ \}\ from\ './lib/ai/factory'}
\DoxyCodeLine{}
\DoxyCodeLine{//\ Create\ a\ basic\ AI\ service}
\DoxyCodeLine{const\ aiService\ =\ createAIService(\{}
\DoxyCodeLine{\ \ provider:\ 'openai',}
\DoxyCodeLine{\ \ //\ Other\ provider-\/specific\ options}
\DoxyCodeLine{\})}
\DoxyCodeLine{}
\DoxyCodeLine{//\ Use\ the\ service}
\DoxyCodeLine{const\ response\ =\ await\ aiService.complete(\{}
\DoxyCodeLine{\ \ model:\ 'gpt-\/4o',}
\DoxyCodeLine{\ \ messages:\ [}
\DoxyCodeLine{\ \ \ \ \{\ role:\ 'system',\ content:\ 'You\ are\ a\ helpful\ assistant.'\ \},}
\DoxyCodeLine{\ \ \ \ \{\ role:\ 'user',\ content:\ 'Hello,\ how\ are\ you?'\ \}}
\DoxyCodeLine{\ \ ]}
\DoxyCodeLine{\})}

\end{DoxyCode}
\hypertarget{README.md_autotoc_md37460}{}\doxysubsubsubsection{\texorpdfstring{With Advanced Performance Optimization}{With Advanced Performance Optimization}}\label{README.md_autotoc_md37460}

\begin{DoxyCode}{0}
\DoxyCodeLine{import\ \{\ createAIService\ \}\ from\ './lib/ai/factory'}
\DoxyCodeLine{}
\DoxyCodeLine{//\ Create\ an\ AI\ service\ with\ advanced\ performance\ optimization}
\DoxyCodeLine{const\ aiService\ =\ createAIService(\{}
\DoxyCodeLine{\ \ provider:\ 'openai',}
\DoxyCodeLine{\ \ enableAdvancedOptimization:\ true,}
\DoxyCodeLine{\ \ advancedPerformanceOptions:\ \{}
\DoxyCodeLine{\ \ \ \ enableCache:\ true,}
\DoxyCodeLine{\ \ \ \ cacheTTL:\ 3600,\ //\ 1\ hour}
\DoxyCodeLine{\ \ \ \ enableRateLimit:\ true,}
\DoxyCodeLine{\ \ \ \ maxRequestsPerMinute:\ 100,}
\DoxyCodeLine{\ \ \ \ enableTokenOptimization:\ true,}
\DoxyCodeLine{\ \ \ \ maxContextLength:\ 4000,}
\DoxyCodeLine{\ \ \ \ enableBatching:\ true,}
\DoxyCodeLine{\ \ \ \ batchWindow:\ 50,\ //\ ms}
\DoxyCodeLine{\ \ \ \ maxBatchSize:\ 5,}
\DoxyCodeLine{\ \ \ \ enableFallback:\ true,}
\DoxyCodeLine{\ \ \ \ fallbackModels:\ ['gpt-\/3.5-\/turbo'],}
\DoxyCodeLine{\ \ \ \ enableDetailedTracking:\ true}
\DoxyCodeLine{\ \ \}}
\DoxyCodeLine{\})}

\end{DoxyCode}
\hypertarget{README.md_autotoc_md37461}{}\doxysubsubsection{\texorpdfstring{Advanced Performance Features}{Advanced Performance Features}}\label{README.md_autotoc_md37461}
\hypertarget{README.md_autotoc_md37462}{}\doxysubsubsubsection{\texorpdfstring{Caching}{Caching}}\label{README.md_autotoc_md37462}
The caching system stores responses to identical requests to reduce latency and costs. Cached responses are stored with a configurable TTL (Time To Live).


\begin{DoxyCode}{0}
\DoxyCodeLine{//\ Configure\ caching}
\DoxyCodeLine{const\ aiService\ =\ createAIService(\{}
\DoxyCodeLine{\ \ provider:\ 'openai',}
\DoxyCodeLine{\ \ enableAdvancedOptimization:\ true,}
\DoxyCodeLine{\ \ advancedPerformanceOptions:\ \{}
\DoxyCodeLine{\ \ \ \ enableCache:\ true,}
\DoxyCodeLine{\ \ \ \ cacheTTL:\ 3600\ //\ 1\ hour\ in\ seconds}
\DoxyCodeLine{\ \ \}}
\DoxyCodeLine{\})}

\end{DoxyCode}
\hypertarget{README.md_autotoc_md37463}{}\doxysubsubsubsection{\texorpdfstring{Rate Limiting}{Rate Limiting}}\label{README.md_autotoc_md37463}
Rate limiting prevents excessive API usage by limiting the number of requests per user within a time window.


\begin{DoxyCode}{0}
\DoxyCodeLine{//\ Configure\ rate\ limiting}
\DoxyCodeLine{const\ aiService\ =\ createAIService(\{}
\DoxyCodeLine{\ \ provider:\ 'openai',}
\DoxyCodeLine{\ \ enableAdvancedOptimization:\ true,}
\DoxyCodeLine{\ \ advancedPerformanceOptions:\ \{}
\DoxyCodeLine{\ \ \ \ enableRateLimit:\ true,}
\DoxyCodeLine{\ \ \ \ maxRequestsPerMinute:\ 100}
\DoxyCodeLine{\ \ \}}
\DoxyCodeLine{\})}

\end{DoxyCode}
\hypertarget{README.md_autotoc_md37464}{}\doxysubsubsubsection{\texorpdfstring{Token Optimization}{Token Optimization}}\label{README.md_autotoc_md37464}
Token optimization reduces token usage by intelligently truncating conversation history while preserving context.


\begin{DoxyCode}{0}
\DoxyCodeLine{//\ Configure\ token\ optimization}
\DoxyCodeLine{const\ aiService\ =\ createAIService(\{}
\DoxyCodeLine{\ \ provider:\ 'openai',}
\DoxyCodeLine{\ \ enableAdvancedOptimization:\ true,}
\DoxyCodeLine{\ \ advancedPerformanceOptions:\ \{}
\DoxyCodeLine{\ \ \ \ enableTokenOptimization:\ true,}
\DoxyCodeLine{\ \ \ \ maxContextLength:\ 4000}
\DoxyCodeLine{\ \ \}}
\DoxyCodeLine{\})}

\end{DoxyCode}
\hypertarget{README.md_autotoc_md37465}{}\doxysubsubsubsection{\texorpdfstring{Request Batching}{Request Batching}}\label{README.md_autotoc_md37465}
Request batching combines multiple requests into batches to reduce overhead and improve throughput.


\begin{DoxyCode}{0}
\DoxyCodeLine{//\ Configure\ request\ batching}
\DoxyCodeLine{const\ aiService\ =\ createAIService(\{}
\DoxyCodeLine{\ \ provider:\ 'openai',}
\DoxyCodeLine{\ \ enableAdvancedOptimization:\ true,}
\DoxyCodeLine{\ \ advancedPerformanceOptions:\ \{}
\DoxyCodeLine{\ \ \ \ enableBatching:\ true,}
\DoxyCodeLine{\ \ \ \ batchWindow:\ 50,\ //\ ms}
\DoxyCodeLine{\ \ \ \ maxBatchSize:\ 5}
\DoxyCodeLine{\ \ \}}
\DoxyCodeLine{\})}

\end{DoxyCode}
\hypertarget{README.md_autotoc_md37466}{}\doxysubsubsubsection{\texorpdfstring{Fallback Models}{Fallback Models}}\label{README.md_autotoc_md37466}
Fallback models provide reliability by automatically switching to alternative models when the primary model fails.


\begin{DoxyCode}{0}
\DoxyCodeLine{//\ Configure\ fallback\ models}
\DoxyCodeLine{const\ aiService\ =\ createAIService(\{}
\DoxyCodeLine{\ \ provider:\ 'openai',}
\DoxyCodeLine{\ \ enableAdvancedOptimization:\ true,}
\DoxyCodeLine{\ \ advancedPerformanceOptions:\ \{}
\DoxyCodeLine{\ \ \ \ enableFallback:\ true,}
\DoxyCodeLine{\ \ \ \ fallbackModels:\ ['gpt-\/3.5-\/turbo',\ 'text-\/davinci-\/003']}
\DoxyCodeLine{\ \ \}}
\DoxyCodeLine{\})}

\end{DoxyCode}
\hypertarget{README.md_autotoc_md37467}{}\doxysubsubsubsection{\texorpdfstring{Performance Tracking}{Performance Tracking}}\label{README.md_autotoc_md37467}
Performance tracking collects detailed metrics on AI service usage, including latency, token usage, success rates, and more.


\begin{DoxyCode}{0}
\DoxyCodeLine{//\ Configure\ performance\ tracking}
\DoxyCodeLine{const\ aiService\ =\ createAIService(\{}
\DoxyCodeLine{\ \ provider:\ 'openai',}
\DoxyCodeLine{\ \ enableAdvancedOptimization:\ true,}
\DoxyCodeLine{\ \ advancedPerformanceOptions:\ \{}
\DoxyCodeLine{\ \ \ \ enableDetailedTracking:\ true}
\DoxyCodeLine{\ \ \}}
\DoxyCodeLine{\})}

\end{DoxyCode}
\hypertarget{README.md_autotoc_md37468}{}\doxysubsubsection{\texorpdfstring{Performance Dashboard}{Performance Dashboard}}\label{README.md_autotoc_md37468}
The AI performance dashboard provides a comprehensive view of AI service performance metrics, including\+:


\begin{DoxyItemize}
\item Request counts
\item Average latency
\item Token usage
\item Success rates
\item Model breakdown
\item Error distribution
\end{DoxyItemize}

Access the dashboard at {\ttfamily /admin/ai/performance}.\hypertarget{README.md_autotoc_md37469}{}\doxysubsubsection{\texorpdfstring{Database Schema}{Database Schema}}\label{README.md_autotoc_md37469}
Performance metrics are stored in the {\ttfamily ai\+\_\+performance\+\_\+metrics} table with the following schema\+:

\tabulinesep=1mm
\begin{longtabu}spread 0pt [c]{*{3}{|X[-1]}|}
\hline
\PBS\centering \cellcolor{\tableheadbgcolor}\textbf{ Column   }&\PBS\centering \cellcolor{\tableheadbgcolor}\textbf{ Type   }&\PBS\centering \cellcolor{\tableheadbgcolor}\textbf{ Description    }\\\cline{1-3}
\endfirsthead
\hline
\endfoot
\hline
\PBS\centering \cellcolor{\tableheadbgcolor}\textbf{ Column   }&\PBS\centering \cellcolor{\tableheadbgcolor}\textbf{ Type   }&\PBS\centering \cellcolor{\tableheadbgcolor}\textbf{ Description    }\\\cline{1-3}
\endhead
id   &uuid   &Primary key    \\\cline{1-3}
model   &text   &AI model name    \\\cline{1-3}
latency   &integer   &Request latency in ms    \\\cline{1-3}
input\+\_\+tokens   &integer   &Number of input tokens    \\\cline{1-3}
output\+\_\+tokens   &integer   &Number of output tokens    \\\cline{1-3}
total\+\_\+tokens   &integer   &Total tokens used    \\\cline{1-3}
success   &boolean   &Whether the request was successful    \\\cline{1-3}
error\+\_\+code   &text   &Error code if request failed    \\\cline{1-3}
cached   &boolean   &Whether the response was cached    \\\cline{1-3}
optimized   &boolean   &Whether token optimization was applied    \\\cline{1-3}
user\+\_\+id   &uuid   &User ID    \\\cline{1-3}
session\+\_\+id   &text   &Session ID    \\\cline{1-3}
request\+\_\+id   &uuid   &Unique request ID    \\\cline{1-3}
timestamp   &timestamp   &Request timestamp   \\\cline{1-3}
\end{longtabu}
