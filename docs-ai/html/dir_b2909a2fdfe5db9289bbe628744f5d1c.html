<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.13.2"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Gradiant Ascent: src/lib/ai Directory Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<script type="text/javascript" src="clipboard.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="cookie.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
  $(function() { init_search(); });
/* @license-end */
</script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">Gradiant Ascent
   </div>
  </td>
    <td>        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <span id="MSearchSelect"                onmouseover="return searchBox.OnSearchSelectShow()"                onmouseout="return searchBox.OnSearchSelectHide()">&#160;</span>
          <input type="text" id="MSearchField" value="" placeholder="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.svg" alt=""/></a>
          </span>
        </div>
</td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.13.2 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() { codefold.init(0); });
/* @license-end */
</script>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function(){initNavTree('dir_b2909a2fdfe5db9289bbe628744f5d1c.html',''); initResizable(true); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div class="header">
  <div class="headertitle"><div class="title">ai Directory Reference</div></div>
</div><!--header-->
<div class="contents">
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="subdirs" name="subdirs"></a>
Directories</h2></td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top"><span class="iconfclosed"></span>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="dir_4736f6c5f583938e3d84c034d4281ac5.html">mental-arena</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top"><span class="iconfclosed"></span>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="dir_110183797cf1009d70eebe8f13d9b8d4.html">mental-llama</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top"><span class="iconfclosed"></span>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="dir_bf9f6ea2b0d861aa068a88f8ba01b82f.html">providers</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<p>This module provides a comprehensive set of tools for integrating AI capabilities into the application. It includes services for sentiment analysis, crisis detection, response generation, and intervention analysis, as well as utilities for error handling and performance optimization.</p>
<h1><a class="anchor" id="autotoc_md37426"></a>
Table of Contents</h1>
<ul>
<li><a class="el" href="md_node__modules_2safer-buffer_2_porting-_buffer.html#overview">Overview</a></li>
<li>Services</li>
<li>Error Handling</li>
<li>Performance Optimization</li>
<li>Usage Examples</li>
<li>API Reference</li>
</ul>
<h1><a class="anchor" id="autotoc_md37427"></a>
Overview</h1>
<p>The AI module is designed to provide a unified interface for interacting with various AI providers, including OpenAI and Anthropic. It abstracts away the details of the underlying APIs and provides a consistent interface for all AI-related functionality.</p>
<p>Key features include:</p>
<ul>
<li>Support for multiple AI providers (OpenAI, Anthropic)</li>
<li>Specialized services for common AI tasks</li>
<li>Comprehensive error handling</li>
<li>Performance optimization with caching and metrics</li>
<li>HIPAA-compliant audit logging</li>
</ul>
<h1><a class="anchor" id="autotoc_md37428"></a>
Services</h1>
<h2><a class="anchor" id="autotoc_md37429"></a>
AI Service Factory</h2>
<p>The <code>createAIService</code> function creates an AI service with the specified provider and options. It automatically applies error handling and performance optimization wrappers.</p>
<div class="fragment"><div class="line">import { createAIService } from &#39;../lib/ai&#39;</div>
<div class="line"> </div>
<div class="line">const aiService = createAIService({</div>
<div class="line">  provider: &#39;openai&#39;, // or &#39;anthropic&#39;</div>
<div class="line">  enableErrorHandling: true,</div>
<div class="line">  enablePerformanceOptimization: true</div>
<div class="line">})</div>
</div><!-- fragment --><h2><a class="anchor" id="autotoc_md37430"></a>
Sentiment Analysis</h2>
<p>The <code>SentimentAnalysisService</code> analyzes the sentiment of text, providing a score and explanation.</p>
<div class="fragment"><div class="line">import { createAIService, SentimentAnalysisService } from &#39;../lib/ai&#39;</div>
<div class="line"> </div>
<div class="line">const aiService = createAIService()</div>
<div class="line">const sentimentService = new SentimentAnalysisService({ aiService })</div>
<div class="line"> </div>
<div class="line">const result = await sentimentService.analyzeSentiment(&#39;I am feeling great today!&#39;)</div>
<div class="line">// { sentiment: &#39;positive&#39;, score: 0.85, explanation: &#39;...&#39;, model: &#39;...&#39;, processingTime: 123 }</div>
</div><!-- fragment --><h2><a class="anchor" id="autotoc_md37431"></a>
Crisis Detection</h2>
<p>The <code>CrisisDetectionService</code> detects potential crisis situations in text, providing a risk level and explanation.</p>
<div class="fragment"><div class="line">import { createAIService, CrisisDetectionService } from &#39;../lib/ai&#39;</div>
<div class="line"> </div>
<div class="line">const aiService = createAIService()</div>
<div class="line">const crisisService = new CrisisDetectionService({ aiService })</div>
<div class="line"> </div>
<div class="line">const result = await crisisService.detectCrisis(&#39;I am feeling really down lately.&#39;)</div>
<div class="line">// { is_crisis: true, risk_level: &#39;low&#39;, crisis_type: &#39;depression&#39;, confidence: 0.65, ... }</div>
</div><!-- fragment --><h2><a class="anchor" id="autotoc_md37432"></a>
Response Generation</h2>
<p>The <code>ResponseGenerationService</code> generates responses to user messages, with support for streaming.</p>
<div class="fragment"><div class="line">import { createAIService, ResponseGenerationService } from &#39;../lib/ai&#39;</div>
<div class="line"> </div>
<div class="line">const aiService = createAIService()</div>
<div class="line">const responseService = new ResponseGenerationService({ aiService })</div>
<div class="line"> </div>
<div class="line">const result = await responseService.generateResponse([</div>
<div class="line">  { role: &#39;user&#39;, content: &#39;Hello, how are you?&#39; }</div>
<div class="line">])</div>
<div class="line">// { response: &#39;I am doing well, thank you!&#39;, model: &#39;...&#39;, processingTime: 123 }</div>
</div><!-- fragment --><h2><a class="anchor" id="autotoc_md37433"></a>
Intervention Analysis</h2>
<p>The <code>InterventionAnalysisService</code> analyzes the effectiveness of therapeutic interventions.</p>
<div class="fragment"><div class="line">import { createAIService, InterventionAnalysisService } from &#39;../lib/ai&#39;</div>
<div class="line"> </div>
<div class="line">const aiService = createAIService()</div>
<div class="line">const interventionService = new InterventionAnalysisService({ aiService })</div>
<div class="line"> </div>
<div class="line">const result = await interventionService.analyzeIntervention(</div>
<div class="line">  conversation,</div>
<div class="line">  interventionMessage,</div>
<div class="line">  userResponse</div>
<div class="line">)</div>
<div class="line">// { effectiveness_score: 8, user_receptiveness: &#39;high&#39;, emotional_impact: &#39;positive&#39;, ... }</div>
</div><!-- fragment --><h1><a class="anchor" id="autotoc_md37434"></a>
Error Handling</h1>
<p>The AI module includes a comprehensive error handling system that standardizes errors across different providers and provides detailed error information.</p>
<h2><a class="anchor" id="autotoc_md37435"></a>
AIError Class</h2>
<p>The <code>AIError</code> class is a custom error class for AI-related errors. It includes a code, status code, context, and original error.</p>
<div class="fragment"><div class="line">import { AIError, AIErrorCodes } from &#39;../lib/ai&#39;</div>
<div class="line"> </div>
<div class="line">throw new AIError(&#39;The AI service is currently unavailable&#39;, {</div>
<div class="line">  code: AIErrorCodes.SERVICE_UNAVAILABLE,</div>
<div class="line">  statusCode: 503,</div>
<div class="line">  context: { model: &#39;gpt-4o&#39; }</div>
<div class="line">})</div>
</div><!-- fragment --><h2><a class="anchor" id="autotoc_md37436"></a>
Error Handling Utilities</h2>
<p>The module includes utilities for handling errors from AI services and transforming them into standardized AIErrors.</p>
<div class="fragment"><div class="line">import { AIErrorCodes, handleAIServiceError } from &#39;../lib/ai&#39;</div>
<div class="line"> </div>
<div class="line">try {</div>
<div class="line">  // Call AI service</div>
<div class="line">}</div>
<div class="line">catch (error) {</div>
<div class="line">  const aiError = handleAIServiceError(error, { model: &#39;gpt-4o&#39; })</div>
<div class="line">  console.error(`AI Error: ${aiError.message} (${aiError.code})`)</div>
<div class="line">}</div>
</div><!-- fragment --><h2><a class="anchor" id="autotoc_md37437"></a>
API Error Handling</h2>
<p>The module includes a utility for handling errors in API routes and returning appropriate responses.</p>
<div class="fragment"><div class="line">import { handleApiError } from &#39;../lib/ai&#39;</div>
<div class="line"> </div>
<div class="line">try {</div>
<div class="line">  // API route logic</div>
<div class="line">}</div>
<div class="line">catch (error) {</div>
<div class="line">  return handleApiError(error)</div>
<div class="line">}</div>
</div><!-- fragment --><h1><a class="anchor" id="autotoc_md37438"></a>
Performance Optimization</h1>
<p>The AI module includes utilities for optimizing the performance of AI services, including caching and metrics collection.</p>
<h2><a class="anchor" id="autotoc_md37439"></a>
Optimized AI Service</h2>
<p>The <code>createOptimizedAIService</code> function creates a performance-optimized AI service wrapper.</p>
<div class="fragment"><div class="line">import { createOptimizedAIService } from &#39;../lib/ai&#39;</div>
<div class="line"> </div>
<div class="line">const optimizedService = createOptimizedAIService(aiService, {</div>
<div class="line">  logToConsole: true,</div>
<div class="line">  createAuditLogs: true,</div>
<div class="line">  slowRequestThreshold: 3000,</div>
<div class="line">  highTokenUsageThreshold: 1000</div>
<div class="line">})</div>
</div><!-- fragment --><h2><a class="anchor" id="autotoc_md37440"></a>
Token Usage Optimization</h2>
<p>The module includes utilities for estimating token usage and truncating messages to fit within token limits.</p>
<div class="fragment"><div class="line">import { estimateMessagesTokenCount, truncateMessages } from &#39;../lib/ai&#39;</div>
<div class="line"> </div>
<div class="line">const tokenCount = estimateMessagesTokenCount(messages)</div>
<div class="line">console.log(`Estimated token count: ${tokenCount}`)</div>
<div class="line"> </div>
<div class="line">const truncatedMessages = truncateMessages(messages, 4000, 1000)</div>
</div><!-- fragment --><h1><a class="anchor" id="autotoc_md37441"></a>
Usage Examples</h1>
<h2><a class="anchor" id="autotoc_md37442"></a>
Basic Usage</h2>
<div class="fragment"><div class="line">import { createAIService } from &#39;../lib/ai&#39;</div>
<div class="line"> </div>
<div class="line">const aiService = createAIService()</div>
<div class="line"> </div>
<div class="line">const completion = await aiService.createChatCompletion(</div>
<div class="line">  [{ role: &#39;user&#39;, content: &#39;Hello, how are you?&#39; }],</div>
<div class="line">  { model: &#39;gpt-4o&#39; }</div>
<div class="line">)</div>
<div class="line"> </div>
<div class="line">console.log(completion.content)</div>
</div><!-- fragment --><h2><a class="anchor" id="autotoc_md37443"></a>
Streaming Response</h2>
<div class="fragment"><div class="line">import { createAIService } from &#39;../lib/ai&#39;</div>
<div class="line"> </div>
<div class="line">const aiService = createAIService()</div>
<div class="line"> </div>
<div class="line">const { stream } = await aiService.createStreamingChatCompletion(</div>
<div class="line">  [{ role: &#39;user&#39;, content: &#39;Hello, how are you?&#39; }],</div>
<div class="line">  { model: &#39;gpt-4o&#39; }</div>
<div class="line">)</div>
<div class="line"> </div>
<div class="line">for await (const chunk of stream) {</div>
<div class="line">  process.stdout.write(chunk.content)</div>
<div class="line">}</div>
</div><!-- fragment --><h2><a class="anchor" id="autotoc_md37444"></a>
Error Handling</h2>
<div class="fragment"><div class="line">import { AIError, AIErrorCodes, createAIService } from &#39;../lib/ai&#39;</div>
<div class="line"> </div>
<div class="line">const aiService = createAIService()</div>
<div class="line"> </div>
<div class="line">try {</div>
<div class="line">  const completion = await aiService.createChatCompletion(</div>
<div class="line">    [{ role: &#39;user&#39;, content: &#39;Hello, how are you?&#39; }],</div>
<div class="line">    { model: &#39;invalid-model&#39; }</div>
<div class="line">  )</div>
<div class="line">}</div>
<div class="line">catch (error) {</div>
<div class="line">  if (error instanceof AIError &amp;&amp; error.code === AIErrorCodes.INVALID_MODEL) {</div>
<div class="line">    console.error(&#39;Invalid model specified&#39;)</div>
<div class="line">  }</div>
<div class="line">  else {</div>
<div class="line">    console.error(&#39;An unexpected error occurred:&#39;, error)</div>
<div class="line">  }</div>
<div class="line">}</div>
</div><!-- fragment --><h2><a class="anchor" id="autotoc_md37445"></a>
Retry with Exponential Backoff</h2>
<div class="fragment"><div class="line">import { createAIService, withRetry } from &#39;../lib/ai&#39;</div>
<div class="line"> </div>
<div class="line">const aiService = createAIService()</div>
<div class="line"> </div>
<div class="line">const completion = await withRetry(</div>
<div class="line">  () =&gt; aiService.createChatCompletion(</div>
<div class="line">    [{ role: &#39;user&#39;, content: &#39;Hello, how are you?&#39; }],</div>
<div class="line">    { model: &#39;gpt-4o&#39; }</div>
<div class="line">  ),</div>
<div class="line">  {</div>
<div class="line">    maxRetries: 3,</div>
<div class="line">    initialDelay: 500,</div>
<div class="line">    maxDelay: 10000,</div>
<div class="line">    factor: 2</div>
<div class="line">  }</div>
<div class="line">)</div>
</div><!-- fragment --><h1><a class="anchor" id="autotoc_md37446"></a>
API Reference</h1>
<h2><a class="anchor" id="autotoc_md37447"></a>
AI Service</h2>
<div class="fragment"><div class="line">interface AIService {</div>
<div class="line">  createChatCompletion: (</div>
<div class="line">    messages: AIMessage[],</div>
<div class="line">    options?: AIServiceOptions</div>
<div class="line">  ) =&gt; Promise&lt;AICompletion&gt;</div>
<div class="line"> </div>
<div class="line">  createStreamingChatCompletion: (</div>
<div class="line">    messages: AIMessage[],</div>
<div class="line">    options?: AIServiceOptions</div>
<div class="line">  ) =&gt; Promise&lt;AIStreamingCompletion&gt;</div>
<div class="line"> </div>
<div class="line">  getModelInfo: (model: string) =&gt; ModelInfo</div>
<div class="line">}</div>
</div><!-- fragment --><h2><a class="anchor" id="autotoc_md37448"></a>
AI Message</h2>
<div class="fragment"><div class="line">interface AIMessage {</div>
<div class="line">  role: &#39;system&#39; | &#39;user&#39; | &#39;assistant&#39;</div>
<div class="line">  content: string</div>
<div class="line">}</div>
</div><!-- fragment --><h2><a class="anchor" id="autotoc_md37449"></a>
AI Completion</h2>
<div class="fragment"><div class="line">interface AICompletion {</div>
<div class="line">  content: string</div>
<div class="line">  model: string</div>
<div class="line">  usage?: {</div>
<div class="line">    prompt_tokens: number</div>
<div class="line">    completion_tokens: number</div>
<div class="line">    total_tokens: number</div>
<div class="line">  }</div>
<div class="line">}</div>
</div><!-- fragment --><h2><a class="anchor" id="autotoc_md37450"></a>
AI Streaming Completion</h2>
<div class="fragment"><div class="line">interface AIStreamingCompletion {</div>
<div class="line">  stream: AsyncIterable&lt;{ content: string }&gt;</div>
<div class="line">  model: string</div>
<div class="line">}</div>
</div><!-- fragment --><h2><a class="anchor" id="autotoc_md37451"></a>
AI Service Options</h2>
<div class="fragment"><div class="line">interface AIServiceOptions {</div>
<div class="line">  model: string</div>
<div class="line">  temperature?: number</div>
<div class="line">  max_tokens?: number</div>
<div class="line">  top_p?: number</div>
<div class="line">  frequency_penalty?: number</div>
<div class="line">  presence_penalty?: number</div>
<div class="line">}</div>
</div><!-- fragment --><h2><a class="anchor" id="autotoc_md37452"></a>
Sentiment Analysis Result</h2>
<div class="fragment"><div class="line">interface SentimentAnalysisResult {</div>
<div class="line">  sentiment: &#39;positive&#39; | &#39;negative&#39; | &#39;neutral&#39;</div>
<div class="line">  score: number</div>
<div class="line">  explanation: string</div>
<div class="line">  model: string</div>
<div class="line">  processingTime: number</div>
<div class="line">}</div>
</div><!-- fragment --><h2><a class="anchor" id="autotoc_md37453"></a>
Crisis Detection Result</h2>
<div class="fragment"><div class="line">interface CrisisDetectionResult {</div>
<div class="line">  is_crisis: boolean</div>
<div class="line">  risk_level: &#39;high&#39; | &#39;medium&#39; | &#39;low&#39; | &#39;none&#39;</div>
<div class="line">  crisis_type: string | null</div>
<div class="line">  confidence: number</div>
<div class="line">  reasoning: string</div>
<div class="line">  model: string</div>
<div class="line">  processingTime: number</div>
<div class="line">}</div>
</div><!-- fragment --><h2><a class="anchor" id="autotoc_md37454"></a>
Response Generation Result</h2>
<div class="fragment"><div class="line">interface ResponseGenerationResult {</div>
<div class="line">  response: string</div>
<div class="line">  model: string</div>
<div class="line">  processingTime: number</div>
<div class="line">  usage?: {</div>
<div class="line">    total_tokens: number</div>
<div class="line">    prompt_tokens: number</div>
<div class="line">    completion_tokens: number</div>
<div class="line">  }</div>
<div class="line">}</div>
</div><!-- fragment --><h2><a class="anchor" id="autotoc_md37455"></a>
Intervention Analysis Result</h2>
<div class="fragment"><div class="line">interface InterventionEffectivenessResult {</div>
<div class="line">  effectiveness_score: number</div>
<div class="line">  user_receptiveness: &#39;high&#39; | &#39;medium&#39; | &#39;low&#39;</div>
<div class="line">  emotional_impact: &#39;positive&#39; | &#39;neutral&#39; | &#39;negative&#39;</div>
<div class="line">  key_insights: string[]</div>
<div class="line">  improvement_suggestions: string[]</div>
<div class="line">  model: string</div>
<div class="line">  processingTime: number</div>
<div class="line">}</div>
</div><!-- fragment --><h1><a class="anchor" id="autotoc_md37456"></a>
AI Service Library</h1>
<p>This library provides a comprehensive set of tools for working with AI services in a HIPAA-compliant environment.</p>
<h2><a class="anchor" id="autotoc_md37457"></a>
Features</h2>
<ul>
<li>Multiple AI provider support (OpenAI, Anthropic, Gemini, Azure OpenAI)</li>
<li>Advanced performance optimization</li>
<li>Comprehensive error handling</li>
<li>Detailed performance tracking and analytics</li>
<li>HIPAA-compliant audit logging</li>
</ul>
<h2><a class="anchor" id="autotoc_md37458"></a>
Usage</h2>
<h3><a class="anchor" id="autotoc_md37459"></a>
Basic Usage</h3>
<div class="fragment"><div class="line">import { createAIService } from &#39;./lib/ai/factory&#39;</div>
<div class="line"> </div>
<div class="line">// Create a basic AI service</div>
<div class="line">const aiService = createAIService({</div>
<div class="line">  provider: &#39;openai&#39;,</div>
<div class="line">  // Other provider-specific options</div>
<div class="line">})</div>
<div class="line"> </div>
<div class="line">// Use the service</div>
<div class="line">const response = await aiService.complete({</div>
<div class="line">  model: &#39;gpt-4o&#39;,</div>
<div class="line">  messages: [</div>
<div class="line">    { role: &#39;system&#39;, content: &#39;You are a helpful assistant.&#39; },</div>
<div class="line">    { role: &#39;user&#39;, content: &#39;Hello, how are you?&#39; }</div>
<div class="line">  ]</div>
<div class="line">})</div>
</div><!-- fragment --><h3><a class="anchor" id="autotoc_md37460"></a>
With Advanced Performance Optimization</h3>
<div class="fragment"><div class="line">import { createAIService } from &#39;./lib/ai/factory&#39;</div>
<div class="line"> </div>
<div class="line">// Create an AI service with advanced performance optimization</div>
<div class="line">const aiService = createAIService({</div>
<div class="line">  provider: &#39;openai&#39;,</div>
<div class="line">  enableAdvancedOptimization: true,</div>
<div class="line">  advancedPerformanceOptions: {</div>
<div class="line">    enableCache: true,</div>
<div class="line">    cacheTTL: 3600, // 1 hour</div>
<div class="line">    enableRateLimit: true,</div>
<div class="line">    maxRequestsPerMinute: 100,</div>
<div class="line">    enableTokenOptimization: true,</div>
<div class="line">    maxContextLength: 4000,</div>
<div class="line">    enableBatching: true,</div>
<div class="line">    batchWindow: 50, // ms</div>
<div class="line">    maxBatchSize: 5,</div>
<div class="line">    enableFallback: true,</div>
<div class="line">    fallbackModels: [&#39;gpt-3.5-turbo&#39;],</div>
<div class="line">    enableDetailedTracking: true</div>
<div class="line">  }</div>
<div class="line">})</div>
</div><!-- fragment --><h2><a class="anchor" id="autotoc_md37461"></a>
Advanced Performance Features</h2>
<h3><a class="anchor" id="autotoc_md37462"></a>
Caching</h3>
<p>The caching system stores responses to identical requests to reduce latency and costs. Cached responses are stored with a configurable TTL (Time To Live).</p>
<div class="fragment"><div class="line">// Configure caching</div>
<div class="line">const aiService = createAIService({</div>
<div class="line">  provider: &#39;openai&#39;,</div>
<div class="line">  enableAdvancedOptimization: true,</div>
<div class="line">  advancedPerformanceOptions: {</div>
<div class="line">    enableCache: true,</div>
<div class="line">    cacheTTL: 3600 // 1 hour in seconds</div>
<div class="line">  }</div>
<div class="line">})</div>
</div><!-- fragment --><h3><a class="anchor" id="autotoc_md37463"></a>
Rate Limiting</h3>
<p>Rate limiting prevents excessive API usage by limiting the number of requests per user within a time window.</p>
<div class="fragment"><div class="line">// Configure rate limiting</div>
<div class="line">const aiService = createAIService({</div>
<div class="line">  provider: &#39;openai&#39;,</div>
<div class="line">  enableAdvancedOptimization: true,</div>
<div class="line">  advancedPerformanceOptions: {</div>
<div class="line">    enableRateLimit: true,</div>
<div class="line">    maxRequestsPerMinute: 100</div>
<div class="line">  }</div>
<div class="line">})</div>
</div><!-- fragment --><h3><a class="anchor" id="autotoc_md37464"></a>
Token Optimization</h3>
<p>Token optimization reduces token usage by intelligently truncating conversation history while preserving context.</p>
<div class="fragment"><div class="line">// Configure token optimization</div>
<div class="line">const aiService = createAIService({</div>
<div class="line">  provider: &#39;openai&#39;,</div>
<div class="line">  enableAdvancedOptimization: true,</div>
<div class="line">  advancedPerformanceOptions: {</div>
<div class="line">    enableTokenOptimization: true,</div>
<div class="line">    maxContextLength: 4000</div>
<div class="line">  }</div>
<div class="line">})</div>
</div><!-- fragment --><h3><a class="anchor" id="autotoc_md37465"></a>
Request Batching</h3>
<p>Request batching combines multiple requests into batches to reduce overhead and improve throughput.</p>
<div class="fragment"><div class="line">// Configure request batching</div>
<div class="line">const aiService = createAIService({</div>
<div class="line">  provider: &#39;openai&#39;,</div>
<div class="line">  enableAdvancedOptimization: true,</div>
<div class="line">  advancedPerformanceOptions: {</div>
<div class="line">    enableBatching: true,</div>
<div class="line">    batchWindow: 50, // ms</div>
<div class="line">    maxBatchSize: 5</div>
<div class="line">  }</div>
<div class="line">})</div>
</div><!-- fragment --><h3><a class="anchor" id="autotoc_md37466"></a>
Fallback Models</h3>
<p>Fallback models provide reliability by automatically switching to alternative models when the primary model fails.</p>
<div class="fragment"><div class="line">// Configure fallback models</div>
<div class="line">const aiService = createAIService({</div>
<div class="line">  provider: &#39;openai&#39;,</div>
<div class="line">  enableAdvancedOptimization: true,</div>
<div class="line">  advancedPerformanceOptions: {</div>
<div class="line">    enableFallback: true,</div>
<div class="line">    fallbackModels: [&#39;gpt-3.5-turbo&#39;, &#39;text-davinci-003&#39;]</div>
<div class="line">  }</div>
<div class="line">})</div>
</div><!-- fragment --><h3><a class="anchor" id="autotoc_md37467"></a>
Performance Tracking</h3>
<p>Performance tracking collects detailed metrics on AI service usage, including latency, token usage, success rates, and more.</p>
<div class="fragment"><div class="line">// Configure performance tracking</div>
<div class="line">const aiService = createAIService({</div>
<div class="line">  provider: &#39;openai&#39;,</div>
<div class="line">  enableAdvancedOptimization: true,</div>
<div class="line">  advancedPerformanceOptions: {</div>
<div class="line">    enableDetailedTracking: true</div>
<div class="line">  }</div>
<div class="line">})</div>
</div><!-- fragment --><h2><a class="anchor" id="autotoc_md37468"></a>
Performance Dashboard</h2>
<p>The AI performance dashboard provides a comprehensive view of AI service performance metrics, including:</p>
<ul>
<li>Request counts</li>
<li>Average latency</li>
<li>Token usage</li>
<li>Success rates</li>
<li>Model breakdown</li>
<li>Error distribution</li>
</ul>
<p>Access the dashboard at <code>/admin/ai/performance</code>.</p>
<h2><a class="anchor" id="autotoc_md37469"></a>
Database Schema</h2>
<p>Performance metrics are stored in the <code>ai_performance_metrics</code> table with the following schema:</p>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadNone">Column   </th><th class="markdownTableHeadNone">Type   </th><th class="markdownTableHeadNone">Description    </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">id   </td><td class="markdownTableBodyNone">uuid   </td><td class="markdownTableBodyNone">Primary key    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">model   </td><td class="markdownTableBodyNone">text   </td><td class="markdownTableBodyNone">AI model name    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">latency   </td><td class="markdownTableBodyNone">integer   </td><td class="markdownTableBodyNone">Request latency in ms    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">input_tokens   </td><td class="markdownTableBodyNone">integer   </td><td class="markdownTableBodyNone">Number of input tokens    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">output_tokens   </td><td class="markdownTableBodyNone">integer   </td><td class="markdownTableBodyNone">Number of output tokens    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">total_tokens   </td><td class="markdownTableBodyNone">integer   </td><td class="markdownTableBodyNone">Total tokens used    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">success   </td><td class="markdownTableBodyNone">boolean   </td><td class="markdownTableBodyNone">Whether the request was successful    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">error_code   </td><td class="markdownTableBodyNone">text   </td><td class="markdownTableBodyNone">Error code if request failed    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">cached   </td><td class="markdownTableBodyNone">boolean   </td><td class="markdownTableBodyNone">Whether the response was cached    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">optimized   </td><td class="markdownTableBodyNone">boolean   </td><td class="markdownTableBodyNone">Whether token optimization was applied    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">user_id   </td><td class="markdownTableBodyNone">uuid   </td><td class="markdownTableBodyNone">User ID    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">session_id   </td><td class="markdownTableBodyNone">text   </td><td class="markdownTableBodyNone">Session ID    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">request_id   </td><td class="markdownTableBodyNone">uuid   </td><td class="markdownTableBodyNone">Unique request ID    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">timestamp   </td><td class="markdownTableBodyNone">timestamp   </td><td class="markdownTableBodyNone">Request timestamp   </td></tr>
</table>
</div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><a class="el" href="dir_68267d1309a1af8e8297ef4c3efbcdba.html">src</a></li><li class="navelem"><a class="el" href="dir_c85d3e3c5052e9ad9ce18c6863244a25.html">lib</a></li><li class="navelem"><a class="el" href="dir_b2909a2fdfe5db9289bbe628744f5d1c.html">ai</a></li>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.13.2 </li>
  </ul>
</div>
</body>
</html>
