<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.13.2"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Gradiant Ascent: node_modules/bottleneck Directory Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<script type="text/javascript" src="clipboard.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="cookie.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
  $(function() { init_search(); });
/* @license-end */
</script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">Gradiant Ascent
   </div>
  </td>
    <td>        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <span id="MSearchSelect"                onmouseover="return searchBox.OnSearchSelectShow()"                onmouseout="return searchBox.OnSearchSelectHide()">&#160;</span>
          <input type="text" id="MSearchField" value="" placeholder="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.svg" alt=""/></a>
          </span>
        </div>
</td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.13.2 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() { codefold.init(0); });
/* @license-end */
</script>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function(){initNavTree('dir_864405c4800ea03f6b19c6ade7d3d21e.html',''); initResizable(true); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div class="header">
  <div class="headertitle"><div class="title">bottleneck Directory Reference</div></div>
</div><!--header-->
<div class="contents">
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<p><a href="https://www.npmjs.com/package/bottleneck"><img src="https://img.shields.io/npm/dm/bottleneck.svg?style=flat" alt="Downloads" style="pointer-events: none;" class="inline"/></a> <a href="https://www.npmjs.com/package/bottleneck"><img src="https://img.shields.io/npm/v/bottleneck.svg?style=flat" alt="version" style="pointer-events: none;" class="inline"/></a> <a href="https://github.com/SGrondin/bottleneck/blob/master/LICENSE"><img src="https://img.shields.io/npm/l/bottleneck.svg?style=flat" alt="License" style="pointer-events: none;" class="inline"/></a></p>
<p>Bottleneck is a lightweight and zero-dependency Task Scheduler and Rate Limiter for Node.js and the browser.</p>
<p>Bottleneck is an easy solution as it adds very little complexity to your code. It is battle-hardened, reliable and production-ready and used on a large scale in private companies and open source software.</p>
<p>It supports <b>Clustering</b>: it can rate limit jobs across multiple Node.js instances. It uses Redis and strictly atomic operations to stay reliable in the presence of unreliable clients and networks. It also supports <em>Redis Cluster</em> and <em>Redis Sentinel</em>.</p>
<p><b>Upgrading from version 1?</b></p>
<ul>
<li>Install</li>
<li>Quick Start<ul>
<li>Gotchas &amp; Common Mistakes</li>
</ul>
</li>
<li>Constructor</li>
<li>Reservoir Intervals</li>
<li>`submit()`</li>
<li>`schedule()`</li>
<li>`wrap()`</li>
<li>Job Options</li>
<li>Jobs Lifecycle</li>
<li>Events</li>
<li>Retries</li>
<li>`updateSettings()`</li>
<li>`incrementReservoir()`</li>
<li>`currentReservoir()`</li>
<li>`stop()`</li>
<li>`chain()`</li>
<li><a class="el" href="/Users/vivi/astro/node_modules/d3-array/README.md#group">Group</a></li>
<li>Batching</li>
<li>Clustering</li>
<li>Debugging Your Application</li>
<li>Upgrading To v2</li>
<li><a class="el" href="md_node__modules_2chai_2_c_o_n_t_r_i_b_u_t_i_n_g.html#contributing">Contributing</a></li>
</ul>
<h1><a class="anchor" id="autotoc_md9440"></a>
Install</h1>
<div class="fragment"><div class="line">npm install --save bottleneck</div>
</div><!-- fragment --><div class="fragment"><div class="line">import Bottleneck from &quot;bottleneck&quot;;</div>
<div class="line"> </div>
<div class="line">// Note: To support older browsers and Node &lt;6.0, you must import the ES5 bundle instead.</div>
<div class="line">var Bottleneck = require(&quot;bottleneck/es5&quot;);</div>
</div><!-- fragment --><h1><a class="anchor" id="autotoc_md9441"></a>
Quick Start</h1>
<h2><a class="anchor" id="autotoc_md9442"></a>
Step 1 of 3</h2>
<p>Most APIs have a rate limit. For example, to execute 3 requests per second: </p><div class="fragment"><div class="line">const limiter = new Bottleneck({</div>
<div class="line">  minTime: 333</div>
<div class="line">});</div>
</div><!-- fragment --><p>If there's a chance some requests might take longer than 333ms and you want to prevent more than 1 request from running at a time, add <code>maxConcurrent: 1</code>: </p><div class="fragment"><div class="line">const limiter = new Bottleneck({</div>
<div class="line">  maxConcurrent: 1,</div>
<div class="line">  minTime: 333</div>
<div class="line">});</div>
</div><!-- fragment --><p><code>minTime</code> and <code>maxConcurrent</code> are enough for the majority of use cases. They work well together to ensure a smooth rate of requests. If your use case requires executing requests in <b>bursts</b> or every time a quota resets, look into Reservoir Intervals.</p>
<h2><a class="anchor" id="autotoc_md9443"></a>
Step 2 of 3</h2>
<h3><a class="anchor" id="autotoc_md9444"></a>
➤ Using promises?</h3>
<p>Instead of this: </p><div class="fragment"><div class="line">myFunction(arg1, arg2)</div>
<div class="line">.then((result) =&gt; {</div>
<div class="line">  /* handle result */</div>
<div class="line">});</div>
</div><!-- fragment --><p> Do this: </p><div class="fragment"><div class="line">limiter.schedule(() =&gt; myFunction(arg1, arg2))</div>
<div class="line">.then((result) =&gt; {</div>
<div class="line">  /* handle result */</div>
<div class="line">});</div>
</div><!-- fragment --><p> Or this: </p><div class="fragment"><div class="line">const wrapped = limiter.wrap(myFunction);</div>
<div class="line"> </div>
<div class="line">wrapped(arg1, arg2)</div>
<div class="line">.then((result) =&gt; {</div>
<div class="line">  /* handle result */</div>
<div class="line">});</div>
</div><!-- fragment --><h3><a class="anchor" id="autotoc_md9445"></a>
➤ Using async/await?</h3>
<p>Instead of this: </p><div class="fragment"><div class="line">const result = await myFunction(arg1, arg2);</div>
</div><!-- fragment --><p> Do this: </p><div class="fragment"><div class="line">const result = await limiter.schedule(() =&gt; myFunction(arg1, arg2));</div>
</div><!-- fragment --><p> Or this: </p><div class="fragment"><div class="line">const wrapped = limiter.wrap(myFunction);</div>
<div class="line"> </div>
<div class="line">const result = await wrapped(arg1, arg2);</div>
</div><!-- fragment --><h3><a class="anchor" id="autotoc_md9446"></a>
➤ Using callbacks?</h3>
<p>Instead of this: </p><div class="fragment"><div class="line">someAsyncCall(arg1, arg2, callback);</div>
</div><!-- fragment --><p> Do this: </p><div class="fragment"><div class="line">limiter.submit(someAsyncCall, arg1, arg2, callback);</div>
</div><!-- fragment --><h2><a class="anchor" id="autotoc_md9447"></a>
Step 3 of 3</h2>
<p>Remember...</p>
<p>Bottleneck builds a queue of jobs and executes them as soon as possible. By default, the jobs will be executed in the order they were received.</p>
<p><b>Read the 'Gotchas' and you're good to go</b>. Or keep reading to learn about all the fine tuning and advanced options available. If your rate limits need to be enforced across a cluster of computers, read the Clustering docs.</p>
<p>Need help debugging your application?</p>
<p>Instead of throttling maybe you want to batch up requests into fewer calls?</p>
<h2><a class="anchor" id="autotoc_md9448"></a>
Gotchas &amp; Common Mistakes</h2>
<ul>
<li>Make sure the function you pass to <code>schedule()</code> or <code>wrap()</code> only returns once <b>all the work it does</b> has completed.</li>
</ul>
<p>Instead of this: </p><div class="fragment"><div class="line">limiter.schedule(() =&gt; {</div>
<div class="line">  tasksArray.forEach(x =&gt; processTask(x));</div>
<div class="line">  // BAD, we return before our processTask() functions are finished processing!</div>
<div class="line">});</div>
</div><!-- fragment --><p> Do this: </p><div class="fragment"><div class="line">limiter.schedule(() =&gt; {</div>
<div class="line">  const allTasks = tasksArray.map(x =&gt; processTask(x));</div>
<div class="line">  // GOOD, we wait until all tasks are done.</div>
<div class="line">  return Promise.all(allTasks);</div>
<div class="line">});</div>
</div><!-- fragment --><ul>
<li>If you're passing an object's method as a job, you'll probably need to <code>bind()</code> the object: <div class="fragment"><div class="line">// instead of this:</div>
<div class="line">limiter.schedule(object.doSomething);</div>
<div class="line">// do this:</div>
<div class="line">limiter.schedule(object.doSomething.bind(object));</div>
<div class="line">// or, wrap it in an arrow function instead:</div>
<div class="line">limiter.schedule(() =&gt; object.doSomething());</div>
</div><!-- fragment --></li>
<li>Bottleneck requires Node 6+ to function. However, an ES5 build is included: <code>var Bottleneck = require("bottleneck/es5");</code>.</li>
<li>Make sure you're catching <code>"error"</code> events emitted by your limiters!</li>
<li>Consider setting a <code>maxConcurrent</code> value instead of leaving it <code>null</code>. This can help your application's performance, especially if you think the limiter's queue might become very long.</li>
<li>If you plan on using <code>priorities</code>, make sure to set a <code>maxConcurrent</code> value.</li>
<li><b>When using <code>submit()</code></b>, if a callback isn't necessary, you must pass <code>null</code> or an empty function instead. It will not work otherwise.</li>
<li><b>When using <code>submit()</code></b>, make sure all the jobs will eventually complete by calling their callback, or set an `expiration`. Even if you submitted your job with a <code>null</code> callback , it still needs to call its callback. This is particularly important if you are using a <code>maxConcurrent</code> value that isn't <code>null</code> (unlimited), otherwise those not completed jobs will be clogging up the limiter and no new jobs will be allowed to run. It's safe to call the callback more than once, subsequent calls are ignored.</li>
</ul>
<h1><a class="anchor" id="autotoc_md9449"></a>
Docs</h1>
<h2><a class="anchor" id="autotoc_md9450"></a>
Constructor</h2>
<div class="fragment"><div class="line">const limiter = new Bottleneck({/* options */});</div>
</div><!-- fragment --><p>Basic options:</p>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadNone">Option   </th><th class="markdownTableHeadNone">Default   </th><th class="markdownTableHeadNone">Description    </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone"><code>maxConcurrent</code>   </td><td class="markdownTableBodyNone"><code>null</code> (unlimited)   </td><td class="markdownTableBodyNone">How many jobs can be executing at the same time. Consider setting a value instead of leaving it <code>null</code>, it can help your application's performance, especially if you think the limiter's queue might get very long.    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone"><code>minTime</code>   </td><td class="markdownTableBodyNone"><code>0</code> ms   </td><td class="markdownTableBodyNone">How long to wait after launching a job before launching another one.    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone"><code>highWater</code>   </td><td class="markdownTableBodyNone"><code>null</code> (unlimited)   </td><td class="markdownTableBodyNone">How long can the queue be? When the queue length exceeds that value, the selected <code>strategy</code> is executed to shed the load.    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone"><code>strategy</code>   </td><td class="markdownTableBodyNone"><code>Bottleneck.strategy.LEAK</code>   </td><td class="markdownTableBodyNone">Which strategy to use when the queue gets longer than the high water mark. Read about strategies. Strategies are never executed if <code>highWater</code> is <code>null</code>.    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone"><code>penalty</code>   </td><td class="markdownTableBodyNone"><code>15 * minTime</code>, or <code>5000</code> when <code>minTime</code> is <code>0</code>   </td><td class="markdownTableBodyNone">The <code>penalty</code> value used by the <code>BLOCK</code> strategy.    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone"><code>reservoir</code>   </td><td class="markdownTableBodyNone"><code>null</code> (unlimited)   </td><td class="markdownTableBodyNone">How many jobs can be executed before the limiter stops executing jobs. If <code>reservoir</code> reaches <code>0</code>, no jobs will be executed until it is no longer <code>0</code>. New jobs will still be queued up.    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone"><code>reservoirRefreshInterval</code>   </td><td class="markdownTableBodyNone"><code>null</code> (disabled)   </td><td class="markdownTableBodyNone">Every <code>reservoirRefreshInterval</code> milliseconds, the <code>reservoir</code> value will be automatically updated to the value of <code>reservoirRefreshAmount</code>. The <code>reservoirRefreshInterval</code> value should be a <a href="https://github.com/SGrondin/bottleneck/issues/88">multiple of 250 (5000 for Clustering)</a>.    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone"><code>reservoirRefreshAmount</code>   </td><td class="markdownTableBodyNone"><code>null</code> (disabled)   </td><td class="markdownTableBodyNone">The value to set <code>reservoir</code> to when <code>reservoirRefreshInterval</code> is in use.    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone"><code>reservoirIncreaseInterval</code>   </td><td class="markdownTableBodyNone"><code>null</code> (disabled)   </td><td class="markdownTableBodyNone">Every <code>reservoirIncreaseInterval</code> milliseconds, the <code>reservoir</code> value will be automatically incremented by <code>reservoirIncreaseAmount</code>. The <code>reservoirIncreaseInterval</code> value should be a <a href="https://github.com/SGrondin/bottleneck/issues/88">multiple of 250 (5000 for Clustering)</a>.    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone"><code>reservoirIncreaseAmount</code>   </td><td class="markdownTableBodyNone"><code>null</code> (disabled)   </td><td class="markdownTableBodyNone">The increment applied to <code>reservoir</code> when <code>reservoirIncreaseInterval</code> is in use.    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone"><code>reservoirIncreaseMaximum</code>   </td><td class="markdownTableBodyNone"><code>null</code> (disabled)   </td><td class="markdownTableBodyNone">The maximum value that <code>reservoir</code> can reach when <code>reservoirIncreaseInterval</code> is in use.    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone"><code>Promise</code>   </td><td class="markdownTableBodyNone"><code>Promise</code> (built-in)   </td><td class="markdownTableBodyNone">This lets you override the Promise library used by Bottleneck.   </td></tr>
</table>
<h2><a class="anchor" id="autotoc_md9451"></a>
Reservoir Intervals</h2>
<p>Reservoir Intervals let you execute requests in bursts, by automatically controlling the limiter's <code>reservoir</code> value. The <code>reservoir</code> is simply the number of jobs the limiter is allowed to execute. Once the value reaches 0, it stops starting new jobs.</p>
<p>There are 2 types of Reservoir Intervals: Refresh Intervals and Increase Intervals.</p>
<h3><a class="anchor" id="autotoc_md9452"></a>
Refresh Interval</h3>
<p>In this example, we throttle to 100 requests every 60 seconds:</p>
<div class="fragment"><div class="line">const limiter = new Bottleneck({</div>
<div class="line">  reservoir: 100, // initial value</div>
<div class="line">  reservoirRefreshAmount: 100,</div>
<div class="line">  reservoirRefreshInterval: 60 * 1000, // must be divisible by 250</div>
<div class="line"> </div>
<div class="line">  // also use maxConcurrent and/or minTime for safety</div>
<div class="line">  maxConcurrent: 1,</div>
<div class="line">  minTime: 333 // pick a value that makes sense for your use case</div>
<div class="line">});</div>
</div><!-- fragment --><p> <code>reservoir</code> is a counter decremented every time a job is launched, we set its initial value to 100. Then, every <code>reservoirRefreshInterval</code> (60000 ms), <code>reservoir</code> is automatically updated to be equal to the <code>reservoirRefreshAmount</code> (100).</p>
<h3><a class="anchor" id="autotoc_md9453"></a>
Increase Interval</h3>
<p>In this example, we throttle jobs to meet the Shopify API Rate Limits. Users are allowed to send 40 requests initially, then every second grants 2 more requests up to a maximum of 40.</p>
<div class="fragment"><div class="line">const limiter = new Bottleneck({</div>
<div class="line">  reservoir: 40, // initial value</div>
<div class="line">  reservoirIncreaseAmount: 2,</div>
<div class="line">  reservoirIncreaseInterval: 1000, // must be divisible by 250</div>
<div class="line">  reservoirIncreaseMaximum: 40,</div>
<div class="line"> </div>
<div class="line">  // also use maxConcurrent and/or minTime for safety</div>
<div class="line">  maxConcurrent: 5,</div>
<div class="line">  minTime: 250 // pick a value that makes sense for your use case</div>
<div class="line">});</div>
</div><!-- fragment --><h3><a class="anchor" id="autotoc_md9454"></a>
Warnings</h3>
<p>Reservoir Intervals are an advanced feature, please take the time to read and understand the following warnings.</p>
<ul>
<li><b>Reservoir Intervals are not a replacement for <code>minTime</code> and <code>maxConcurrent</code>.</b> It's strongly recommended to also use <code>minTime</code> and/or <code>maxConcurrent</code> to spread out the load. For example, suppose a lot of jobs are queued up because the <code>reservoir</code> is 0. Every time the Refresh Interval is triggered, a number of jobs equal to <code>reservoirRefreshAmount</code> will automatically be launched, all at the same time! To prevent this flooding effect and keep your application running smoothly, use <code>minTime</code> and <code>maxConcurrent</code> to <b>stagger</b> the jobs.</li>
<li><b>The Reservoir Interval starts from the moment the limiter is created</b>. Let's suppose we're using <code>reservoirRefreshAmount: 5</code>. If you happen to add 10 jobs just 1ms before the refresh is triggered, the first 5 will run immediately, then 1ms later it will refresh the reservoir value and that will make the last 5 also run right away. It will have run 10 jobs in just over 1ms no matter what your reservoir interval was!</li>
<li><b>Reservoir Intervals prevent a limiter from being garbage collected.</b> Call <code>limiter.disconnect()</code> to clear the interval and allow the memory to be freed. However, it's not necessary to call <code>.disconnect()</code> to allow the Node.js process to exit.</li>
</ul>
<h2><a class="anchor" id="autotoc_md9455"></a>
submit()</h2>
<p>Adds a job to the queue. This is the callback version of <code>schedule()</code>. </p><div class="fragment"><div class="line">limiter.submit(someAsyncCall, arg1, arg2, callback);</div>
</div><!-- fragment --><p> You can pass <code>null</code> instead of an empty function if there is no callback, but <code>someAsyncCall</code> still needs to call <b>its</b> callback to let the limiter know it has completed its work.</p>
<p><code>submit()</code> can also accept advanced options.</p>
<h2><a class="anchor" id="autotoc_md9456"></a>
schedule()</h2>
<p>Adds a job to the queue. This is the Promise and async/await version of <code>submit()</code>. </p><div class="fragment"><div class="line">const fn = function(arg1, arg2) {</div>
<div class="line">  return httpGet(arg1, arg2); // Here httpGet() returns a promise</div>
<div class="line">};</div>
<div class="line"> </div>
<div class="line">limiter.schedule(fn, arg1, arg2)</div>
<div class="line">.then((result) =&gt; {</div>
<div class="line">  /* ... */</div>
<div class="line">});</div>
</div><!-- fragment --><p> In other words, <code>schedule()</code> takes a function <b>fn</b> and a list of arguments. <code>schedule()</code> returns a promise that will be executed according to the rate limits.</p>
<p><code>schedule()</code> can also accept advanced options.</p>
<p>Here's another example: </p><div class="fragment"><div class="line">// suppose that `client.get(url)` returns a promise</div>
<div class="line"> </div>
<div class="line">const url = &quot;https://wikipedia.org&quot;;</div>
<div class="line"> </div>
<div class="line">limiter.schedule(() =&gt; client.get(url))</div>
<div class="line">.then(response =&gt; console.log(response.body));</div>
</div><!-- fragment --><h2><a class="anchor" id="autotoc_md9457"></a>
wrap()</h2>
<p>Takes a function that returns a promise. Returns a function identical to the original, but rate limited. </p><div class="fragment"><div class="line">const wrapped = limiter.wrap(fn);</div>
<div class="line"> </div>
<div class="line">wrapped()</div>
<div class="line">.then(function (result) {</div>
<div class="line">  /* ... */</div>
<div class="line">})</div>
<div class="line">.catch(function (error) {</div>
<div class="line">  // Bottleneck might need to fail the job even if the original function can never fail.</div>
<div class="line">  // For example, your job is taking longer than the `expiration` time you&#39;ve set.</div>
<div class="line">});</div>
</div><!-- fragment --><h2><a class="anchor" id="autotoc_md9458"></a>
Job Options</h2>
<p><code>submit()</code>, <code>schedule()</code>, and <code>wrap()</code> all accept advanced options. </p><div class="fragment"><div class="line">// Submit</div>
<div class="line">limiter.submit({/* options */}, someAsyncCall, arg1, arg2, callback);</div>
<div class="line"> </div>
<div class="line">// Schedule</div>
<div class="line">limiter.schedule({/* options */}, fn, arg1, arg2);</div>
<div class="line"> </div>
<div class="line">// Wrap</div>
<div class="line">const wrapped = limiter.wrap(fn);</div>
<div class="line">wrapped.withOptions({/* options */}, arg1, arg2);</div>
</div><!-- fragment --><table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadNone">Option   </th><th class="markdownTableHeadNone">Default   </th><th class="markdownTableHeadNone">Description    </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone"><code>priority</code>   </td><td class="markdownTableBodyNone"><code>5</code>   </td><td class="markdownTableBodyNone">A priority between <code>0</code> and <code>9</code>. A job with a priority of <code>4</code> will be queued ahead of a job with a priority of <code>5</code>. <b>Important:</b> You must set a low <code>maxConcurrent</code> value for priorities to work, otherwise there is nothing to queue because jobs will be be scheduled immediately!    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone"><code>weight</code>   </td><td class="markdownTableBodyNone"><code>1</code>   </td><td class="markdownTableBodyNone">Must be an integer equal to or higher than <code>0</code>. The <code>weight</code> is what increases the number of running jobs (up to <code>maxConcurrent</code>) and decreases the <code>reservoir</code> value.    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone"><code>expiration</code>   </td><td class="markdownTableBodyNone"><code>null</code> (unlimited)   </td><td class="markdownTableBodyNone">The number of milliseconds a job is given to complete. Jobs that execute for longer than <code>expiration</code> ms will be failed with a <code>BottleneckError</code>.    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone"><code>id</code>   </td><td class="markdownTableBodyNone"><code>&lt;no-id&gt;</code>   </td><td class="markdownTableBodyNone">You should give an ID to your jobs, it helps with debugging.   </td></tr>
</table>
<h2><a class="anchor" id="autotoc_md9459"></a>
Strategies</h2>
<p>A strategy is a simple algorithm that is executed every time adding a job would cause the number of queued jobs to exceed <code>highWater</code>. Strategies are never executed if <code>highWater</code> is <code>null</code>.</p>
<h3><a class="anchor" id="autotoc_md9460"></a>
Bottleneck.strategy.LEAK</h3>
<p>When adding a new job to a limiter, if the queue length reaches <code>highWater</code>, drop the oldest job with the lowest priority. This is useful when jobs that have been waiting for too long are not important anymore. If all the queued jobs are more important (based on their <code>priority</code> value) than the one being added, it will not be added.</p>
<h3><a class="anchor" id="autotoc_md9461"></a>
Bottleneck.strategy.OVERFLOW_PRIORITY</h3>
<p>Same as <code>LEAK</code>, except it will only drop jobs that are <em>less important</em> than the one being added. If all the queued jobs are as or more important than the new one, it will not be added.</p>
<h3><a class="anchor" id="autotoc_md9462"></a>
Bottleneck.strategy.OVERFLOW</h3>
<p>When adding a new job to a limiter, if the queue length reaches <code>highWater</code>, do not add the new job. This strategy totally ignores priority levels.</p>
<h3><a class="anchor" id="autotoc_md9463"></a>
Bottleneck.strategy.BLOCK</h3>
<p>When adding a new job to a limiter, if the queue length reaches <code>highWater</code>, the limiter falls into "blocked mode". All queued jobs are dropped and no new jobs will be accepted until the limiter unblocks. It will unblock after <code>penalty</code> milliseconds have passed without receiving a new job. <code>penalty</code> is equal to <code>15 * minTime</code> (or <code>5000</code> if <code>minTime</code> is <code>0</code>) by default. This strategy is ideal when bruteforce attacks are to be expected. This strategy totally ignores priority levels.</p>
<h2><a class="anchor" id="autotoc_md9464"></a>
Jobs lifecycle</h2>
<ol type="1">
<li><b>Received</b>. Your new job has been added to the limiter. Bottleneck needs to check whether it can be accepted into the queue.</li>
<li><b>Queued</b>. Bottleneck has accepted your job, but it can not tell at what exact timestamp it will run yet, because it is dependent on previous jobs.</li>
<li><b>Running</b>. Your job is not in the queue anymore, it will be executed after a delay that was computed according to your <code>minTime</code> setting.</li>
<li><b>Executing</b>. Your job is executing its code.</li>
<li><b>Done</b>. Your job has completed.</li>
</ol>
<p><b>Note:</b> By default, Bottleneck does not keep track of DONE jobs, to save memory. You can enable this feature by passing <code>trackDoneStatus: true</code> as an option when creating a limiter.</p>
<h3><a class="anchor" id="autotoc_md9465"></a>
counts()</h3>
<div class="fragment"><div class="line">const counts = limiter.counts();</div>
<div class="line"> </div>
<div class="line">console.log(counts);</div>
<div class="line">/*</div>
<div class="line">{</div>
<div class="line">  RECEIVED: 0,</div>
<div class="line">  QUEUED: 0,</div>
<div class="line">  RUNNING: 0,</div>
<div class="line">  EXECUTING: 0,</div>
<div class="line">  DONE: 0</div>
<div class="line">}</div>
<div class="line">*/</div>
</div><!-- fragment --><p>Returns an object with the current number of jobs per status in the limiter.</p>
<h3><a class="anchor" id="autotoc_md9466"></a>
jobStatus()</h3>
<div class="fragment"><div class="line">console.log(limiter.jobStatus(&quot;some-job-id&quot;));</div>
<div class="line">// Example: QUEUED</div>
</div><!-- fragment --><p>Returns the status of the job with the provided job id <b>in the limiter</b>. Returns <code>null</code> if no job with that id exist.</p>
<h3><a class="anchor" id="autotoc_md9467"></a>
jobs()</h3>
<div class="fragment"><div class="line">console.log(limiter.jobs(&quot;RUNNING&quot;));</div>
<div class="line">// Example: [&#39;id1&#39;, &#39;id2&#39;]</div>
</div><!-- fragment --><p>Returns an array of all the job ids with the specified status <b>in the limiter</b>. Not passing a status string returns all the known ids.</p>
<h3><a class="anchor" id="autotoc_md9468"></a>
queued()</h3>
<div class="fragment"><div class="line">const count = limiter.queued(priority);</div>
<div class="line"> </div>
<div class="line">console.log(count);</div>
</div><!-- fragment --><p><code>priority</code> is optional. Returns the number of <code>QUEUED</code> jobs with the given <code>priority</code> level. Omitting the <code>priority</code> argument returns the total number of queued jobs <b>in the limiter</b>.</p>
<h3><a class="anchor" id="autotoc_md9469"></a>
clusterQueued()</h3>
<div class="fragment"><div class="line">const count = await limiter.clusterQueued();</div>
<div class="line"> </div>
<div class="line">console.log(count);</div>
</div><!-- fragment --><p>Returns the number of <code>QUEUED</code> jobs <b>in the Cluster</b>.</p>
<h3><a class="anchor" id="autotoc_md9470"></a>
empty()</h3>
<div class="fragment"><div class="line">if (limiter.empty()) {</div>
<div class="line">  // do something...</div>
<div class="line">}</div>
</div><!-- fragment --><p>Returns a boolean which indicates whether there are any <code>RECEIVED</code> or <code>QUEUED</code> jobs <b>in the limiter</b>.</p>
<h3><a class="anchor" id="autotoc_md9471"></a>
running()</h3>
<div class="fragment"><div class="line">limiter.running()</div>
<div class="line">.then((count) =&gt; console.log(count));</div>
</div><!-- fragment --><p>Returns a promise that returns the <b>total weight</b> of the <code>RUNNING</code> and <code>EXECUTING</code> jobs <b>in the Cluster</b>.</p>
<h3><a class="anchor" id="autotoc_md9472"></a>
done()</h3>
<div class="fragment"><div class="line">limiter.done()</div>
<div class="line">.then((count) =&gt; console.log(count));</div>
</div><!-- fragment --><p>Returns a promise that returns the <b>total weight</b> of <code>DONE</code> jobs <b>in the Cluster</b>. Does not require passing the <code>trackDoneStatus: true</code> option.</p>
<h3><a class="anchor" id="autotoc_md9473"></a>
check()</h3>
<div class="fragment"><div class="line">limiter.check()</div>
<div class="line">.then((wouldRunNow) =&gt; console.log(wouldRunNow));</div>
</div><!-- fragment --><p> Checks if a new job would be executed immediately if it was submitted now. Returns a promise that returns a boolean.</p>
<h2><a class="anchor" id="autotoc_md9474"></a>
Events</h2>
<p><b>'error'</b> </p><div class="fragment"><div class="line">limiter.on(&quot;error&quot;, function (error) {</div>
<div class="line">  /* handle errors here */</div>
<div class="line">});</div>
</div><!-- fragment --><p>The two main causes of error events are: uncaught exceptions in your event handlers, and network errors when Clustering is enabled.</p>
<p><b>'failed'</b> </p><div class="fragment"><div class="line">limiter.on(&quot;failed&quot;, function (error, jobInfo) {</div>
<div class="line">  // This will be called every time a job fails.</div>
<div class="line">});</div>
</div><!-- fragment --><p><b>'retry'</b></p>
<p>See Retries to learn how to automatically retry jobs. </p><div class="fragment"><div class="line">limiter.on(&quot;retry&quot;, function (message, jobInfo) {</div>
<div class="line">  // This will be called every time a job is retried.</div>
<div class="line">});</div>
</div><!-- fragment --><p><b>'empty'</b> </p><div class="fragment"><div class="line">limiter.on(&quot;empty&quot;, function () {</div>
<div class="line">  // This will be called when `limiter.empty()` becomes true.</div>
<div class="line">});</div>
</div><!-- fragment --><p><b>'idle'</b> </p><div class="fragment"><div class="line">limiter.on(&quot;idle&quot;, function () {</div>
<div class="line">  // This will be called when `limiter.empty()` is `true` and `limiter.running()` is `0`.</div>
<div class="line">});</div>
</div><!-- fragment --><p><b>'dropped'</b> </p><div class="fragment"><div class="line">limiter.on(&quot;dropped&quot;, function (dropped) {</div>
<div class="line">  // This will be called when a strategy was triggered.</div>
<div class="line">  // The dropped request is passed to this event listener.</div>
<div class="line">});</div>
</div><!-- fragment --><p><b>'depleted'</b> </p><div class="fragment"><div class="line">limiter.on(&quot;depleted&quot;, function (empty) {</div>
<div class="line">  // This will be called every time the reservoir drops to 0.</div>
<div class="line">  // The `empty` (boolean) argument indicates whether `limiter.empty()` is currently true.</div>
<div class="line">});</div>
</div><!-- fragment --><p><b>'debug'</b> </p><div class="fragment"><div class="line">limiter.on(&quot;debug&quot;, function (message, data) {</div>
<div class="line">  // Useful to figure out what the limiter is doing in real time</div>
<div class="line">  // and to help debug your application</div>
<div class="line">});</div>
</div><!-- fragment --><p><b>'received'</b> <b>'queued'</b> <b>'scheduled'</b> <b>'executing'</b> <b>'done'</b> </p><div class="fragment"><div class="line">limiter.on(&quot;queued&quot;, function (info) {</div>
<div class="line">  // This event is triggered when a job transitions from one Lifecycle stage to another</div>
<div class="line">});</div>
</div><!-- fragment --><p>See Jobs Lifecycle for more information.</p>
<p>These Lifecycle events are not triggered for jobs located on another limiter in a Cluster, for performance reasons.</p>
<h3><a class="anchor" id="autotoc_md9475"></a>
Other event methods</h3>
<p>Use <code>removeAllListeners()</code> with an optional event name as first argument to remove listeners.</p>
<p>Use <code>.once()</code> instead of <code>.on()</code> to only receive a single event.</p>
<h2><a class="anchor" id="autotoc_md9476"></a>
Retries</h2>
<p>The following example: </p><div class="fragment"><div class="line">const limiter = new Bottleneck();</div>
<div class="line"> </div>
<div class="line">// Listen to the &quot;failed&quot; event</div>
<div class="line">limiter.on(&quot;failed&quot;, async (error, jobInfo) =&gt; {</div>
<div class="line">  const id = jobInfo.options.id;</div>
<div class="line">  console.warn(`Job ${id} failed: ${error}`);</div>
<div class="line"> </div>
<div class="line">  if (jobInfo.retryCount === 0) { // Here we only retry once</div>
<div class="line">    console.log(`Retrying job ${id} in 25ms!`);</div>
<div class="line">    return 25;</div>
<div class="line">  }</div>
<div class="line">});</div>
<div class="line"> </div>
<div class="line">// Listen to the &quot;retry&quot; event</div>
<div class="line">limiter.on(&quot;retry&quot;, (error, jobInfo) =&gt; console.log(`Now retrying ${jobInfo.options.id}`));</div>
<div class="line"> </div>
<div class="line">const main = async function () {</div>
<div class="line">  let executions = 0;</div>
<div class="line"> </div>
<div class="line">  // Schedule one job</div>
<div class="line">  const result = await limiter.schedule({ id: &#39;ABC123&#39; }, async () =&gt; {</div>
<div class="line">    executions++;</div>
<div class="line">    if (executions === 1) {</div>
<div class="line">      throw new Error(&quot;Boom!&quot;);</div>
<div class="line">    } else {</div>
<div class="line">      return &quot;Success!&quot;;</div>
<div class="line">    }</div>
<div class="line">  });</div>
<div class="line"> </div>
<div class="line">  console.log(`Result: ${result}`);</div>
<div class="line">}</div>
<div class="line"> </div>
<div class="line">main();</div>
</div><!-- fragment --><p> will output </p><div class="fragment"><div class="line">Job ABC123 failed: Error: Boom!</div>
<div class="line">Retrying job ABC123 in 25ms!</div>
<div class="line">Now retrying ABC123</div>
<div class="line">Result: Success!</div>
</div><!-- fragment --><p> To re-run your job, simply return an integer from the &lsquo;'failed&rsquo;<code>event handler. The number returned is how many milliseconds to wait before retrying it. Return</code>0` to retry it immediately.</p>
<p><b>IMPORTANT:</b> When you ask the limiter to retry a job it will not send it back into the queue. It will stay in the <code>EXECUTING</code> state until it succeeds or until you stop retrying it. <b>This means that it counts as a concurrent job for <code>maxConcurrent</code> even while it's just waiting to be retried.</b> The number of milliseconds to wait ignores your <code>minTime</code> settings.</p>
<h2><a class="anchor" id="autotoc_md9477"></a>
updateSettings()</h2>
<div class="fragment"><div class="line">limiter.updateSettings(options);</div>
</div><!-- fragment --><p> The options are the same as the limiter constructor.</p>
<p><b>Note:</b> Changes don't affect <code>SCHEDULED</code> jobs.</p>
<h2><a class="anchor" id="autotoc_md9478"></a>
incrementReservoir()</h2>
<div class="fragment"><div class="line">limiter.incrementReservoir(incrementBy);</div>
</div><!-- fragment --><p> Returns a promise that returns the new reservoir value.</p>
<h2><a class="anchor" id="autotoc_md9479"></a>
currentReservoir()</h2>
<div class="fragment"><div class="line">limiter.currentReservoir()</div>
<div class="line">.then((reservoir) =&gt; console.log(reservoir));</div>
</div><!-- fragment --><p> Returns a promise that returns the current reservoir value.</p>
<h2><a class="anchor" id="autotoc_md9480"></a>
stop()</h2>
<p>The <code>stop()</code> method is used to safely shutdown a limiter. It prevents any new jobs from being added to the limiter and waits for all <code>EXECUTING</code> jobs to complete.</p>
<div class="fragment"><div class="line">limiter.stop(options)</div>
<div class="line">.then(() =&gt; {</div>
<div class="line">  console.log(&quot;Shutdown completed!&quot;)</div>
<div class="line">});</div>
</div><!-- fragment --><p><code>stop()</code> returns a promise that resolves once all the <code>EXECUTING</code> jobs have completed and, if desired, once all non-<code>EXECUTING</code> jobs have been dropped.</p>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadNone">Option   </th><th class="markdownTableHeadNone">Default   </th><th class="markdownTableHeadNone">Description    </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone"><code>dropWaitingJobs</code>   </td><td class="markdownTableBodyNone"><code>true</code>   </td><td class="markdownTableBodyNone">When <code>true</code>, drop all the <code>RECEIVED</code>, <code>QUEUED</code> and <code>RUNNING</code> jobs. When <code>false</code>, allow those jobs to complete before resolving the Promise returned by this method.    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone"><code>dropErrorMessage</code>   </td><td class="markdownTableBodyNone"><code>This limiter has been stopped.</code>   </td><td class="markdownTableBodyNone">The error message used to drop jobs when <code>dropWaitingJobs</code> is <code>true</code>.    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone"><code>enqueueErrorMessage</code>   </td><td class="markdownTableBodyNone"><code>This limiter has been stopped and cannot accept new jobs.</code>   </td><td class="markdownTableBodyNone">The error message used to reject a job added to the limiter after <code>stop()</code> has been called.   </td></tr>
</table>
<h2><a class="anchor" id="autotoc_md9481"></a>
chain()</h2>
<p>Tasks that are ready to be executed will be added to that other limiter. Suppose you have 2 types of tasks, A and B. They both have their own limiter with their own settings, but both must also follow a global limiter G: </p><div class="fragment"><div class="line">const limiterA = new Bottleneck( /* some settings */ );</div>
<div class="line">const limiterB = new Bottleneck( /* some different settings */ );</div>
<div class="line">const limiterG = new Bottleneck( /* some global settings */ );</div>
<div class="line"> </div>
<div class="line">limiterA.chain(limiterG);</div>
<div class="line">limiterB.chain(limiterG);</div>
<div class="line"> </div>
<div class="line">// Requests added to limiterA must follow the A and G rate limits.</div>
<div class="line">// Requests added to limiterB must follow the B and G rate limits.</div>
<div class="line">// Requests added to limiterG must follow the G rate limits.</div>
</div><!-- fragment --><p>To unchain, call <code>limiter.chain(null);</code>.</p>
<h1><a class="anchor" id="autotoc_md9482"></a>
Group</h1>
<p>The <code>Group</code> feature of Bottleneck manages many limiters automatically for you. It creates limiters dynamically and transparently.</p>
<p>Let's take a DNS server as an example of how Bottleneck can be used. It's a service that sees a lot of abuse and where incoming DNS requests need to be rate limited. Bottleneck is so tiny, it's acceptable to create one limiter for each origin IP, even if it means creating thousands of limiters. The <code>Group</code> feature is perfect for this use case. Create one Group and use the origin IP to rate limit each IP independently. Each call with the same key (IP) will be routed to the same underlying limiter. A Group is created like a limiter:</p>
<div class="fragment"><div class="line">const group = new Bottleneck.Group(options);</div>
</div><!-- fragment --><p>The <code>options</code> object will be used for every limiter created by the Group.</p>
<p>The Group is then used with the <code>.key(str)</code> method:</p>
<div class="fragment"><div class="line">// In this example, the key is an IP</div>
<div class="line">group.key(&quot;77.66.54.32&quot;).schedule(() =&gt; {</div>
<div class="line">  /* process the request */</div>
<div class="line">});</div>
</div><!-- fragment --><h3><a class="anchor" id="autotoc_md9483"></a>
key()</h3>
<ul>
<li><code>str</code> : The key to use. All jobs added with the same key will use the same underlying limiter. <em>Default: <code>""</code></em></li>
</ul>
<p>The return value of <code>.key(str)</code> is a limiter. If it doesn't already exist, it is generated for you. Calling <code>key()</code> is how limiters are created inside a Group.</p>
<p>Limiters that have been idle for longer than 5 minutes are deleted to avoid memory leaks, this value can be changed by passing a different <code>timeout</code> option, in milliseconds.</p>
<h3><a class="anchor" id="autotoc_md9484"></a>
on("created")</h3>
<div class="fragment"><div class="line">group.on(&quot;created&quot;, (limiter, key) =&gt; {</div>
<div class="line">  console.log(&quot;A new limiter was created for key: &quot; + key)</div>
<div class="line"> </div>
<div class="line">  // Prepare the limiter, for example we&#39;ll want to listen to its &quot;error&quot; events!</div>
<div class="line">  limiter.on(&quot;error&quot;, (err) =&gt; {</div>
<div class="line">    // Handle errors here</div>
<div class="line">  })</div>
<div class="line">});</div>
</div><!-- fragment --><p>Listening for the <code>"created"</code> event is the recommended way to set up a new limiter. Your event handler is executed before <code>key()</code> returns the newly created limiter.</p>
<h3><a class="anchor" id="autotoc_md9485"></a>
updateSettings()</h3>
<div class="fragment"><div class="line">const group = new Bottleneck.Group({ maxConcurrent: 2, minTime: 250 });</div>
<div class="line">group.updateSettings({ minTime: 500 });</div>
</div><!-- fragment --><p> After executing the above commands, <b>new limiters</b> will be created with <code>{ maxConcurrent: 2, minTime: 500 }</code>.</p>
<h3><a class="anchor" id="autotoc_md9486"></a>
deleteKey()</h3>
<ul>
<li><code>str</code>: The key for the limiter to delete.</li>
</ul>
<p>Manually deletes the limiter at the specified key. When using Clustering, the Redis data is immediately deleted and the other Groups in the Cluster will eventually delete their local key automatically, unless it is still being used.</p>
<h3><a class="anchor" id="autotoc_md9487"></a>
keys()</h3>
<p>Returns an array containing all the keys in the Group.</p>
<h3><a class="anchor" id="autotoc_md9488"></a>
clusterKeys()</h3>
<p>Same as <code>group.keys()</code>, but returns all keys in this Group ID across the Cluster.</p>
<h3><a class="anchor" id="autotoc_md9489"></a>
limiters()</h3>
<div class="fragment"><div class="line">const limiters = group.limiters();</div>
<div class="line"> </div>
<div class="line">console.log(limiters);</div>
<div class="line">// [ { key: &quot;some key&quot;, limiter: &lt;limiter&gt; }, { key: &quot;some other key&quot;, limiter: &lt;some other limiter&gt; } ]</div>
</div><!-- fragment --><h1><a class="anchor" id="autotoc_md9490"></a>
Batching</h1>
<p>Some APIs can accept multiple operations in a single call. Bottleneck's Batching feature helps you take advantage of those APIs: </p><div class="fragment"><div class="line">const batcher = new Bottleneck.Batcher({</div>
<div class="line">  maxTime: 1000,</div>
<div class="line">  maxSize: 10</div>
<div class="line">});</div>
<div class="line"> </div>
<div class="line">batcher.on(&quot;batch&quot;, (batch) =&gt; {</div>
<div class="line">  console.log(batch); // [&quot;some-data&quot;, &quot;some-other-data&quot;]</div>
<div class="line"> </div>
<div class="line">  // Handle batch here</div>
<div class="line">});</div>
<div class="line"> </div>
<div class="line">batcher.add(&quot;some-data&quot;);</div>
<div class="line">batcher.add(&quot;some-other-data&quot;);</div>
</div><!-- fragment --><p><code>batcher.add()</code> returns a Promise that resolves once the request has been flushed to a <code>"batch"</code> event.</p>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadNone">Option   </th><th class="markdownTableHeadNone">Default   </th><th class="markdownTableHeadNone">Description    </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone"><code>maxTime</code>   </td><td class="markdownTableBodyNone"><code>null</code> (unlimited)   </td><td class="markdownTableBodyNone">Maximum acceptable time (in milliseconds) a request can have to wait before being flushed to the <code>"batch"</code> event.    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone"><code>maxSize</code>   </td><td class="markdownTableBodyNone"><code>null</code> (unlimited)   </td><td class="markdownTableBodyNone">Maximum number of requests in a batch.   </td></tr>
</table>
<p>Batching doesn't throttle requests, it only groups them up optimally according to your <code>maxTime</code> and <code>maxSize</code> settings.</p>
<h1><a class="anchor" id="autotoc_md9491"></a>
Clustering</h1>
<p>Clustering lets many limiters access the same shared state, stored in Redis. Changes to the state are Atomic, Consistent and Isolated (and fully <a href="https://en.wikipedia.org/wiki/ACID">ACID</a> with the right <a href="https://redis.io/topics/persistence">Durability</a> configuration), to eliminate any chances of race conditions or state corruption. Your settings, such as <code>maxConcurrent</code>, <code>minTime</code>, etc., are shared across the whole cluster, which means —for example— that <code>{ maxConcurrent: 5 }</code> guarantees no more than 5 jobs can ever run at a time in the entire cluster of limiters. 100% of Bottleneck's features are supported in Clustering mode. Enabling Clustering is as simple as changing a few settings. It's also a convenient way to store or export state for later use.</p>
<p>Bottleneck will attempt to spread load evenly across limiters.</p>
<h2><a class="anchor" id="autotoc_md9492"></a>
Enabling Clustering</h2>
<p>First, add <code>redis</code> or <code>ioredis</code> to your application's dependencies: </p><div class="fragment"><div class="line"># NodeRedis (https://github.com/NodeRedis/node_redis)</div>
<div class="line">npm install --save redis</div>
<div class="line"> </div>
<div class="line"># or ioredis (https://github.com/luin/ioredis)</div>
<div class="line">npm install --save ioredis</div>
</div><!-- fragment --><p> Then create a limiter or a Group: </p><div class="fragment"><div class="line">const limiter = new Bottleneck({</div>
<div class="line">  /* Some basic options */</div>
<div class="line">  maxConcurrent: 5,</div>
<div class="line">  minTime: 500</div>
<div class="line">  id: &quot;my-super-app&quot; // All limiters with the same id will be clustered together</div>
<div class="line"> </div>
<div class="line">  /* Clustering options */</div>
<div class="line">  datastore: &quot;redis&quot;, // or &quot;ioredis&quot;</div>
<div class="line">  clearDatastore: false,</div>
<div class="line">  clientOptions: {</div>
<div class="line">    host: &quot;127.0.0.1&quot;,</div>
<div class="line">    port: 6379</div>
<div class="line"> </div>
<div class="line">    // Redis client options</div>
<div class="line">    // Using NodeRedis? See https://github.com/NodeRedis/node_redis#options-object-properties</div>
<div class="line">    // Using ioredis? See https://github.com/luin/ioredis/blob/master/API.md#new-redisport-host-options</div>
<div class="line">  }</div>
<div class="line">});</div>
</div><!-- fragment --><table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadNone">Option   </th><th class="markdownTableHeadNone">Default   </th><th class="markdownTableHeadNone">Description    </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone"><code>datastore</code>   </td><td class="markdownTableBodyNone"><code>"local"</code>   </td><td class="markdownTableBodyNone">Where the limiter stores its internal state. The default (<code>"local"</code>) keeps the state in the limiter itself. Set it to <code>"redis"</code> or <code>"ioredis"</code> to enable Clustering.    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone"><code>clearDatastore</code>   </td><td class="markdownTableBodyNone"><code>false</code>   </td><td class="markdownTableBodyNone">When set to <code>true</code>, on initial startup, the limiter will wipe any existing Bottleneck state data on the Redis db.    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone"><code>clientOptions</code>   </td><td class="markdownTableBodyNone"><code>{}</code>   </td><td class="markdownTableBodyNone">This object is passed directly to the redis client library you've selected.    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone"><code>clusterNodes</code>   </td><td class="markdownTableBodyNone"><code>null</code>   </td><td class="markdownTableBodyNone"><b>ioredis only.</b> When <code>clusterNodes</code> is not null, the client will be instantiated by calling <code>new Redis.Cluster(clusterNodes, clientOptions)</code> instead of <code>new Redis(clientOptions)</code>.    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone"><code>timeout</code>   </td><td class="markdownTableBodyNone"><code>null</code> (no TTL)   </td><td class="markdownTableBodyNone">The Redis TTL in milliseconds (<a href="https://redis.io/commands/ttl">TTL</a>) for the keys created by the limiter. When <code>timeout</code> is set, the limiter's state will be automatically removed from Redis after <code>timeout</code> milliseconds of inactivity.    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone"><code>Redis</code>   </td><td class="markdownTableBodyNone"><code>null</code>   </td><td class="markdownTableBodyNone">Overrides the import/require of the redis/ioredis library. You shouldn't need to set this option unless your application is failing to start due to a failure to require/import the client library.   </td></tr>
</table>
<p><b>Note: When using Groups</b>, the <code>timeout</code> option has a default of <code>300000</code> milliseconds and the generated limiters automatically receive an <code>id</code> with the pattern <code>${group.id}-${KEY}</code>.</p>
<p><b>Note:</b> If you are seeing a runtime error due to the <code>require()</code> function not being able to load <code>redis</code>/<code>ioredis</code>, then directly pass the module as the <code>Redis</code> option. Example: </p><div class="fragment"><div class="line">import Redis from &quot;ioredis&quot;</div>
<div class="line"> </div>
<div class="line">const limiter = new Bottleneck({</div>
<div class="line">  id: &quot;my-super-app&quot;,</div>
<div class="line">  datastore: &quot;ioredis&quot;,</div>
<div class="line">  clientOptions: { host: &#39;12.34.56.78&#39;, port: 6379 },</div>
<div class="line">  Redis</div>
<div class="line">});</div>
</div><!-- fragment --><p> Unfortunately, this is a side effect of having to disable inlining, which is necessary to make Bottleneck easy to use in the browser.</p>
<h2><a class="anchor" id="autotoc_md9493"></a>
Important considerations when Clustering</h2>
<p>The first limiter connecting to Redis will store its constructor options on Redis and all subsequent limiters will be using those settings. You can alter the constructor options used by all the connected limiters by calling <code>updateSettings()</code>. The <code>clearDatastore</code> option instructs a new limiter to wipe any previous Bottleneck data (for that <code>id</code>), including previously stored settings.</p>
<p>Queued jobs are <b>NOT</b> stored on Redis. They are local to each limiter. Exiting the Node.js process will lose those jobs. This is because Bottleneck has no way to propagate the JS code to run a job across a different Node.js process than the one it originated on. Bottleneck doesn't keep track of the queue contents of the limiters on a cluster for performance and reliability reasons. You can use something like <a href="https://github.com/bee-queue/bee-queue"><code>BeeQueue</code></a> in addition to Bottleneck to get around this limitation.</p>
<p>Due to the above, functionality relying on the queue length happens purely locally:</p><ul>
<li>Priorities are local. A higher priority job will run before a lower priority job <b>on the same limiter</b>. Another limiter on the cluster might run a lower priority job before our higher priority one.</li>
<li>Assuming constant priority levels, Bottleneck guarantees that jobs will be run in the order they were received <b>on the same limiter</b>. Another limiter on the cluster might run a job received later before ours runs.</li>
<li><code>highWater</code> and load shedding (strategies) are per limiter. However, one limiter entering Blocked mode will put the entire cluster in Blocked mode until <code>penalty</code> milliseconds have passed. See Strategies.</li>
<li>The <code>"empty"</code> event is triggered when the (local) queue is empty.</li>
<li>The <code>"idle"</code> event is triggered when the (local) queue is empty <em>and</em> no jobs are currently running anywhere in the cluster.</li>
</ul>
<p>You must work around these limitations in your application code if they are an issue to you. The <code>publish()</code> method could be useful here.</p>
<p>The current design guarantees reliability, is highly performant and lets limiters come and go. Your application can scale up or down, and clients can be disconnected at any time without issues.</p>
<p>It is <b>strongly recommended</b> that you give an <code>id</code> to every limiter and Group since it is used to build the name of your limiter's Redis keys! Limiters with the same <code>id</code> inside the same Redis db will be sharing the same datastore.</p>
<p>It is <b>strongly recommended</b> that you set an <code>expiration</code> (See Job Options) <em>on every job</em>, since that lets the cluster recover from crashed or disconnected clients. Otherwise, a client crashing while executing a job would not be able to tell the cluster to decrease its number of "running" jobs. By using expirations, those lost jobs are automatically cleared after the specified time has passed. Using expirations is essential to keeping a cluster reliable in the face of unpredictable application bugs, network hiccups, and so on.</p>
<p>Network latency between Node.js and Redis is not taken into account when calculating timings (such as <code>minTime</code>). To minimize the impact of latency, Bottleneck only performs a single Redis call per lifecycle transition. Keeping the Redis server close to your limiters will help you get a more consistent experience. Keeping the system time consistent across all clients will also help.</p>
<p>It is <b>strongly recommended</b> to set up an `&quot;error&quot;` listener on all your limiters and on your Groups.</p>
<h2><a class="anchor" id="autotoc_md9494"></a>
Clustering Methods</h2>
<p>The <code>ready()</code>, <code>publish()</code> and <code>clients()</code> methods also exist when using the <code>local</code> datastore, for code compatibility reasons: code written for <code>redis</code>/<code>ioredis</code> won't break with <code>local</code>.</p>
<h3><a class="anchor" id="autotoc_md9495"></a>
ready()</h3>
<p>This method returns a promise that resolves once the limiter is connected to Redis.</p>
<p>As of v2.9.0, it's no longer necessary to wait for <code>.ready()</code> to resolve before issuing commands to a limiter. The commands will be queued until the limiter successfully connects. Make sure to listen to the <code>"error"</code> event to handle connection errors.</p>
<div class="fragment"><div class="line">const limiter = new Bottleneck({/* options */});</div>
<div class="line"> </div>
<div class="line">limiter.on(&quot;error&quot;, (err) =&gt; {</div>
<div class="line">  // handle network errors</div>
<div class="line">});</div>
<div class="line"> </div>
<div class="line">limiter.ready()</div>
<div class="line">.then(() =&gt; {</div>
<div class="line">  // The limiter is ready</div>
<div class="line">});</div>
</div><!-- fragment --><h3><a class="anchor" id="autotoc_md9496"></a>
publish(message)</h3>
<p>This method broadcasts the <code>message</code> string to every limiter in the Cluster. It returns a promise. </p><div class="fragment"><div class="line">const limiter = new Bottleneck({/* options */});</div>
<div class="line"> </div>
<div class="line">limiter.on(&quot;message&quot;, (msg) =&gt; {</div>
<div class="line">  console.log(msg); // prints &quot;this is a string&quot;</div>
<div class="line">});</div>
<div class="line"> </div>
<div class="line">limiter.publish(&quot;this is a string&quot;);</div>
</div><!-- fragment --><p>To send objects, stringify them first: </p><div class="fragment"><div class="line">limiter.on(&quot;message&quot;, (msg) =&gt; {</div>
<div class="line">  console.log(JSON.parse(msg).hello) // prints &quot;world&quot;</div>
<div class="line">});</div>
<div class="line"> </div>
<div class="line">limiter.publish(JSON.stringify({ hello: &quot;world&quot; }));</div>
</div><!-- fragment --><h3><a class="anchor" id="autotoc_md9497"></a>
clients()</h3>
<p>If you need direct access to the redis clients, use <code>.clients()</code>: </p><div class="fragment"><div class="line">console.log(limiter.clients());</div>
<div class="line">// { client: &lt;Redis Client&gt;, subscriber: &lt;Redis Client&gt; }</div>
</div><!-- fragment --><h2><a class="anchor" id="autotoc_md9498"></a>
Additional Clustering information</h2>
<ul>
<li>Bottleneck is compatible with <a href="https://redis.io/topics/cluster-tutorial">Redis Clusters</a>, but you must use the <code>ioredis</code> datastore and the <code>clusterNodes</code> option.</li>
<li>Bottleneck is compatible with Redis Sentinel, but you must use the <code>ioredis</code> datastore.</li>
<li>Bottleneck's data is stored in Redis keys starting with <code>b_</code>. It also uses pubsub channels starting with <code>b_</code> It will not interfere with any other data stored on the server.</li>
<li>Bottleneck loads a few Lua scripts on the Redis server using the <code>SCRIPT LOAD</code> command. These scripts only take up a few Kb of memory. Running the <code>SCRIPT FLUSH</code> command will cause any connected limiters to experience critical errors until a new limiter connects to Redis and loads the scripts again.</li>
<li>The Lua scripts are highly optimized and designed to use as few resources as possible.</li>
</ul>
<h2><a class="anchor" id="autotoc_md9499"></a>
Managing Redis Connections</h2>
<p>Bottleneck needs to create 2 Redis Clients to function, one for normal operations and one for pubsub subscriptions. These 2 clients are kept in a <code>Bottleneck.RedisConnection</code> (NodeRedis) or a <code>Bottleneck.IORedisConnection</code> (ioredis) object, referred to as the Connection object.</p>
<p>By default, every Group and every standalone limiter (a limiter not created by a Group) will create their own Connection object, but it is possible to manually control this behavior. In this example, every Group and limiter is sharing the same Connection object and therefore the same 2 clients: </p><div class="fragment"><div class="line">const connection = new Bottleneck.RedisConnection({</div>
<div class="line">  clientOptions: {/* NodeRedis/ioredis options */}</div>
<div class="line">  // ioredis also accepts `clusterNodes` here</div>
<div class="line">});</div>
<div class="line"> </div>
<div class="line"> </div>
<div class="line">const limiter = new Bottleneck({ connection: connection });</div>
<div class="line">const group = new Bottleneck.Group({ connection: connection });</div>
</div><!-- fragment --><p> You can access and reuse the Connection object of any Group or limiter: </p><div class="fragment"><div class="line">const group = new Bottleneck.Group({ connection: limiter.connection });</div>
</div><!-- fragment --><p> When a Connection object is created manually, the connectivity <code>"error"</code> events are emitted on the Connection itself. </p><div class="fragment"><div class="line">connection.on(&quot;error&quot;, (err) =&gt; { /* handle connectivity errors here */ });</div>
</div><!-- fragment --><p> If you already have a NodeRedis/ioredis client, you can ask Bottleneck to reuse it, although currently the Connection object will still create a second client for pubsub operations: </p><div class="fragment"><div class="line">import Redis from &quot;redis&quot;;</div>
<div class="line">const client = new Redis.createClient({/* options */});</div>
<div class="line"> </div>
<div class="line">const connection = new Bottleneck.RedisConnection({</div>
<div class="line">  // `clientOptions` and `clusterNodes` will be ignored since we&#39;re passing a raw client</div>
<div class="line">  client: client</div>
<div class="line">});</div>
<div class="line"> </div>
<div class="line">const limiter = new Bottleneck({ connection: connection });</div>
<div class="line">const group = new Bottleneck.Group({ connection: connection });</div>
</div><!-- fragment --><p> Depending on your application, using more clients can improve performance.</p>
<p>Use the <code>disconnect(flush)</code> method to close the Redis clients. </p><div class="fragment"><div class="line">limiter.disconnect();</div>
<div class="line">group.disconnect();</div>
</div><!-- fragment --><p> If you created the Connection object manually, you need to call <code>connection.disconnect()</code> instead, for safety reasons.</p>
<h1><a class="anchor" id="autotoc_md9500"></a>
Debugging your application</h1>
<p>Debugging complex scheduling logic can be difficult, especially when priorities, weights, and network latency all interact with one another.</p>
<p>If your application is not behaving as expected, start by making sure you're catching <code>"error"</code> events emitted by your limiters and your Groups. Those errors are most likely uncaught exceptions from your application code.</p>
<p>Make sure you've read the 'Gotchas' section.</p>
<p>To see exactly what a limiter is doing in real time, listen to the <code>"debug"</code> event. It contains detailed information about how the limiter is executing your code. Adding job IDs to all your jobs makes the debug output more readable.</p>
<p>When Bottleneck has to fail one of your jobs, it does so by using <code>BottleneckError</code> objects. This lets you tell those errors apart from your own code's errors: </p><div class="fragment"><div class="line">limiter.schedule(fn)</div>
<div class="line">.then((result) =&gt; { /* ... */ } )</div>
<div class="line">.catch((error) =&gt; {</div>
<div class="line">  if (error instanceof Bottleneck.BottleneckError) {</div>
<div class="line">    /* ... */</div>
<div class="line">  }</div>
<div class="line">});</div>
</div><!-- fragment --><h1><a class="anchor" id="autotoc_md9501"></a>
Upgrading to v2</h1>
<p>The internal algorithms essentially haven't changed from v1, but many small changes to the interface were made to introduce new features.</p>
<p>All the breaking changes:</p><ul>
<li>Bottleneck v2 requires Node 6+ or a modern browser. Use <code>require("bottleneck/es5")</code> if you need ES5 support in v2. Bottleneck v1 will continue to use ES5 only.</li>
<li>The Bottleneck constructor now takes an options object. See Constructor.</li>
<li>The <code>Cluster</code> feature is now called <code>Group</code>. This is to distinguish it from the new v2 Clustering feature.</li>
<li>The <code>Group</code> constructor takes an options object to match the limiter constructor.</li>
<li>Jobs take an optional options object. See Job options.</li>
<li>Removed <code>submitPriority()</code>, use <code>submit()</code> with an options object instead.</li>
<li>Removed <code>schedulePriority()</code>, use <code>schedule()</code> with an options object instead.</li>
<li>The <code>rejectOnDrop</code> option is now <code>true</code> by default. It can be set to <code>false</code> if you wish to retain v1 behavior. However this option is left undocumented as enabling it is considered to be a poor practice.</li>
<li>Use <code>null</code> instead of <code>0</code> to indicate an unlimited <code>maxConcurrent</code> value.</li>
<li>Use <code>null</code> instead of <code>-1</code> to indicate an unlimited <code>highWater</code> value.</li>
<li>Renamed <code>changeSettings()</code> to <code>updateSettings()</code>, it now returns a promise to indicate completion. It takes the same options object as the constructor.</li>
<li>Renamed <code>nbQueued()</code> to <code>queued()</code>.</li>
<li>Renamed <code>nbRunning</code> to <code>running()</code>, it now returns its result using a promise.</li>
<li>Removed <code>isBlocked()</code>.</li>
<li>Changing the Promise library is now done through the options object like any other limiter setting.</li>
<li>Removed <code>changePenalty()</code>, it is now done through the options object like any other limiter setting.</li>
<li>Removed <code>changeReservoir()</code>, it is now done through the options object like any other limiter setting.</li>
<li>Removed <code>stopAll()</code>. Use the new <code>stop()</code> method.</li>
<li><code>check()</code> now accepts an optional <code>weight</code> argument, and returns its result using a promise.</li>
<li>Removed the <code>Group</code> <code>changeTimeout()</code> method. Instead, pass a <code>timeout</code> option when creating a Group.</li>
</ul>
<p>Version 2 is more user-friendly and powerful.</p>
<p>After upgrading your code, please take a minute to read the Debugging your application chapter.</p>
<h1><a class="anchor" id="autotoc_md9502"></a>
Contributing</h1>
<p>This README is always in need of improvements. If wording can be clearer and simpler, please consider forking this repo and submitting a Pull Request, or simply opening an issue.</p>
<p>Suggestions and bug reports are also welcome.</p>
<p>To work on the Bottleneck code, simply clone the repo, makes your changes to the files located in <code>src/</code> only, then run <code>./scripts/build.sh &amp;&amp; npm test</code> to ensure that everything is set up correctly.</p>
<p>To speed up compilation time during development, run <code>./scripts/build.sh dev</code> instead. Make sure to build and test without <code>dev</code> before submitting a PR.</p>
<p>The tests must also pass in Clustering mode and using the ES5 bundle. You'll need a Redis server running locally (latency needs to be minimal to run the tests). If the server isn't using the default hostname and port, you can set those in the <code>.env</code> file. Then run <code>./scripts/build.sh &amp;&amp; npm run test-all</code>.</p>
<p>All contributions are appreciated and will be considered. </p>
</div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><a class="el" href="dir_acd06b18086a0dd2ae699b1e0b775be8.html">node_modules</a></li><li class="navelem"><a class="el" href="dir_864405c4800ea03f6b19c6ade7d3d21e.html">bottleneck</a></li>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.13.2 </li>
  </ul>
</div>
</body>
</html>
